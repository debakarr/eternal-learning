{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Running a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# two tensor constants\n",
    "node1 = tf.constant(30, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "\n",
    "print(node1, node2) # outputs an abstract tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() # use resources such as CPU or GPU\n",
    "print(sess.run([node1, node2]))\n",
    "sess.close() # free up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other way to create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run([node1, node2])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing computational graph using Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done by first creating a tf.summary.FileWriter object, passing the path of the directory where the information will be store that can be use by Tensorboard to create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class FileWriter in module tensorflow.python.summary.writer.writer:\n",
      "\n",
      "class FileWriter(SummaryToEventTransformer)\n",
      " |  Writes `Summary` protocol buffers to event files.\n",
      " |  \n",
      " |  The `FileWriter` class provides a mechanism to create an event file in a\n",
      " |  given directory and add summaries and events to it. The class updates the\n",
      " |  file contents asynchronously. This allows a training program to call methods\n",
      " |  to add data to the file directly from the training loop, without slowing down\n",
      " |  training.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      FileWriter\n",
      " |      SummaryToEventTransformer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None)\n",
      " |      Creates a `FileWriter` and an event file.\n",
      " |      \n",
      " |      On construction the summary writer creates a new event file in `logdir`.\n",
      " |      This event file will contain `Event` protocol buffers constructed when you\n",
      " |      call one of the following functions: `add_summary()`, `add_session_log()`,\n",
      " |      `add_event()`, or `add_graph()`.\n",
      " |      \n",
      " |      If you pass a `Graph` to the constructor it is added to\n",
      " |      the event file. (This is equivalent to calling `add_graph()` later).\n",
      " |      \n",
      " |      TensorBoard will pick the graph from the file and display it graphically so\n",
      " |      you can interactively explore the graph you built. You will usually pass\n",
      " |      the graph from the session in which you launched it:\n",
      " |      \n",
      " |      ```python\n",
      " |      ...create a graph...\n",
      " |      # Launch the graph in a session.\n",
      " |      sess = tf.Session()\n",
      " |      # Create a summary writer, add the 'graph' to the event file.\n",
      " |      writer = tf.summary.FileWriter(<some-directory>, sess.graph)\n",
      " |      ```\n",
      " |      \n",
      " |      The other arguments to the constructor control the asynchronous writes to\n",
      " |      the event file:\n",
      " |      \n",
      " |      *  `flush_secs`: How often, in seconds, to flush the added summaries\n",
      " |         and events to disk.\n",
      " |      *  `max_queue`: Maximum number of summaries or events pending to be\n",
      " |         written to disk before one of the 'add' calls block.\n",
      " |      \n",
      " |      Args:\n",
      " |        logdir: A string. Directory where event file will be written.\n",
      " |        graph: A `Graph` object, such as `sess.graph`.\n",
      " |        max_queue: Integer. Size of the queue for pending events and summaries.\n",
      " |        flush_secs: Number. How often, in seconds, to flush the\n",
      " |          pending events and summaries to disk.\n",
      " |        graph_def: DEPRECATED: Use the `graph` argument instead.\n",
      " |        filename_suffix: A string. Every event file's name is suffixed with\n",
      " |          `suffix`.\n",
      " |  \n",
      " |  add_event(self, event)\n",
      " |      Adds an event to the event file.\n",
      " |      \n",
      " |      Args:\n",
      " |        event: An `Event` protocol buffer.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Flushes the event file to disk and close the file.\n",
      " |      \n",
      " |      Call this method when you do not need the summary writer anymore.\n",
      " |  \n",
      " |  flush(self)\n",
      " |      Flushes the event file to disk.\n",
      " |      \n",
      " |      Call this method to make sure that all pending events have been written to\n",
      " |      disk.\n",
      " |  \n",
      " |  get_logdir(self)\n",
      " |      Returns the directory where event file will be written.\n",
      " |  \n",
      " |  reopen(self)\n",
      " |      Reopens the EventFileWriter.\n",
      " |      \n",
      " |      Can be called after `close()` to add more events in the same directory.\n",
      " |      The events will go into a new events file.\n",
      " |      \n",
      " |      Does nothing if the EventFileWriter was not closed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from SummaryToEventTransformer:\n",
      " |  \n",
      " |  add_graph(self, graph, global_step=None, graph_def=None)\n",
      " |      Adds a `Graph` to the event file.\n",
      " |      \n",
      " |      The graph described by the protocol buffer will be displayed by\n",
      " |      TensorBoard. Most users pass a graph in the constructor instead.\n",
      " |      \n",
      " |      Args:\n",
      " |        graph: A `Graph` object, such as `sess.graph`.\n",
      " |        global_step: Number. Optional global step counter to record with the\n",
      " |          graph.\n",
      " |        graph_def: DEPRECATED. Use the `graph` parameter instead.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If both graph and graph_def are passed to the method.\n",
      " |  \n",
      " |  add_meta_graph(self, meta_graph_def, global_step=None)\n",
      " |      Adds a `MetaGraphDef` to the event file.\n",
      " |      \n",
      " |      The `MetaGraphDef` allows running the given graph via\n",
      " |      `saver.import_meta_graph()`.\n",
      " |      \n",
      " |      Args:\n",
      " |        meta_graph_def: A `MetaGraphDef` object, often as returned by\n",
      " |          `saver.export_meta_graph()`.\n",
      " |        global_step: Number. Optional global step counter to record with the\n",
      " |          graph.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If both `meta_graph_def` is not an instance of `MetaGraphDef`.\n",
      " |  \n",
      " |  add_run_metadata(self, run_metadata, tag, global_step=None)\n",
      " |      Adds a metadata information for a single session.run() call.\n",
      " |      \n",
      " |      Args:\n",
      " |        run_metadata: A `RunMetadata` protobuf object.\n",
      " |        tag: The tag name for this metadata.\n",
      " |        global_step: Number. Optional global step counter to record with the\n",
      " |          StepStats.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided tag was already used for this type of event.\n",
      " |  \n",
      " |  add_session_log(self, session_log, global_step=None)\n",
      " |      Adds a `SessionLog` protocol buffer to the event file.\n",
      " |      \n",
      " |      This method wraps the provided session in an `Event` protocol buffer\n",
      " |      and adds it to the event file.\n",
      " |      \n",
      " |      Args:\n",
      " |        session_log: A `SessionLog` protocol buffer.\n",
      " |        global_step: Number. Optional global step value to record with the\n",
      " |          summary.\n",
      " |  \n",
      " |  add_summary(self, summary, global_step=None)\n",
      " |      Adds a `Summary` protocol buffer to the event file.\n",
      " |      \n",
      " |      This method wraps the provided summary in an `Event` protocol buffer\n",
      " |      and adds it to the event file.\n",
      " |      \n",
      " |      You can pass the result of evaluating any summary op, using\n",
      " |      @{tf.Session.run} or\n",
      " |      @{tf.Tensor.eval}, to this\n",
      " |      function. Alternatively, you can pass a `tf.Summary` protocol\n",
      " |      buffer that you populate with your own data. The latter is\n",
      " |      commonly done to report evaluation results in event files.\n",
      " |      \n",
      " |      Args:\n",
      " |        summary: A `Summary` protocol buffer, optionally serialized as a string.\n",
      " |        global_step: Number. Optional global step value to record with the\n",
      " |          summary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SummaryToEventTransformer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.summary.FileWriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(7.0)\n",
    "b = tf.constant(5.0)\n",
    "\n",
    "c = a * b\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "File_Writer = tf.summary.FileWriter('graph', sess.graph)\n",
    "\n",
    "print(sess.run(c))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the above code the present working directory will have a folder name **graph**. \n",
    "Now we need to go to the terminal and type: \n",
    "```bash \n",
    "tensorflow --logdir='graph' \n",
    "TensorBoard 0.1.5 at http://baka:6006 (Press CTRL+C to quit) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit http://baka:6006. The graph looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial Graph](initial_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.  12.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "adder_node = a + b\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(adder_node, {a:[4, 5], b:[2, 7]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 3.00000238], dtype=float32), array([ 1.99999309], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Model Parameters\n",
    "W = tf.Variable([0.0], tf.float32)\n",
    "b = tf.Variable([0.0], tf.float32)\n",
    "\n",
    "# Inputs and Outputs\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W * x + b\n",
    "\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Loss function\n",
    "squared_error = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_error)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "# This will intialize the global variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init) #Initializing global variables\n",
    "\n",
    "# print(sess.run(loss, {x:[1, 2, 3, 4], y:[5, 8, 11, 14]}))\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1, 2, 3, 4], y:[5, 8, 11, 14]})\n",
    "\n",
    "print(sess.run([W, b]))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Naval Mine Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 61)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090  \\\n",
       "0  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "1  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "2  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "3  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "4  0.3039 ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027  0.0051   \n",
       "\n",
       "   0.0032  R  \n",
       "0  0.0044  R  \n",
       "1  0.0078  R  \n",
       "2  0.0117  R  \n",
       "3  0.0094  R  \n",
       "4  0.0062  R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values # matrix of features/independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0453,  0.0523,  0.0843,  0.0689,  0.1183,  0.2583,  0.2156,\n",
       "        0.3481,  0.3337,  0.2872,  0.4918,  0.6552,  0.6919,  0.7797,\n",
       "        0.7464,  0.9444,  1.    ,  0.8874,  0.8024,  0.7818,  0.5212,\n",
       "        0.4052,  0.3957,  0.3914,  0.325 ,  0.32  ,  0.3271,  0.2767,\n",
       "        0.4423,  0.2028,  0.3788,  0.2947,  0.1984,  0.2341,  0.1306,\n",
       "        0.4182,  0.3835,  0.1057,  0.184 ,  0.197 ,  0.1674,  0.0583,\n",
       "        0.1401,  0.1628,  0.0621,  0.0203,  0.053 ,  0.0742,  0.0409,\n",
       "        0.0061,  0.0125,  0.0084,  0.0089,  0.0048,  0.0094,  0.0191,\n",
       "        0.014 ,  0.0049,  0.0052,  0.0044])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset.iloc[:, -1].values # dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(categorical_features=[0])\n",
    "Y = oneHotEncoder.fit_transform(Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters and variables to work with Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim:  60\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.2\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print('n_dim: ', n_dim)\n",
    "n_class = 2\n",
    "model_save_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining layers and neurons for multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 40\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_3, weights['out'] + biases['out_b'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1]),name=\"h1\"),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2]),name=\"h2\"),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3]),name=\"h3\"),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_3, n_class]),name=\"out\"),\n",
    "    }\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1]),name=\"b1\"),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2]),name=\"b2\"),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3]),name=\"b3\"),\n",
    "    'out_b': tf.Variable(tf.truncated_normal([n_class]),name=\"out_b\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    " \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  -  cost:  778.442  - MSE:  585562.268284 - Train Accuracy:  0.490909\n",
      "epoch:  1  -  cost:  3.98307  - MSE:  42.1137533856 - Train Accuracy:  0.509091\n",
      "epoch:  2  -  cost:  19.8982  - MSE:  447.461636396 - Train Accuracy:  0.490909\n",
      "epoch:  3  -  cost:  0.755463  - MSE:  0.658345415286 - Train Accuracy:  0.490909\n",
      "epoch:  4  -  cost:  0.702614  - MSE:  0.523252043387 - Train Accuracy:  0.490909\n",
      "epoch:  5  -  cost:  0.697171  - MSE:  0.509780570692 - Train Accuracy:  0.484848\n",
      "epoch:  6  -  cost:  0.695005  - MSE:  0.505017091938 - Train Accuracy:  0.539394\n",
      "epoch:  7  -  cost:  0.694942  - MSE:  0.504508735085 - Train Accuracy:  0.551515\n",
      "epoch:  8  -  cost:  0.694887  - MSE:  0.504513941815 - Train Accuracy:  0.539394\n",
      "epoch:  9  -  cost:  0.694832  - MSE:  0.504081258285 - Train Accuracy:  0.551515\n",
      "epoch:  10  -  cost:  0.694779  - MSE:  0.504097736449 - Train Accuracy:  0.539394\n",
      "epoch:  11  -  cost:  0.694725  - MSE:  0.503705170707 - Train Accuracy:  0.551515\n",
      "epoch:  12  -  cost:  0.694679  - MSE:  0.503725003059 - Train Accuracy:  0.539394\n",
      "epoch:  13  -  cost:  0.694622  - MSE:  0.503355673026 - Train Accuracy:  0.551515\n",
      "epoch:  14  -  cost:  0.694589  - MSE:  0.503374546505 - Train Accuracy:  0.521212\n",
      "epoch:  15  -  cost:  0.694589  - MSE:  0.502651702469 - Train Accuracy:  0.563636\n",
      "epoch:  16  -  cost:  0.694502  - MSE:  0.502981853636 - Train Accuracy:  0.515152\n",
      "epoch:  17  -  cost:  0.694534  - MSE:  0.502236062851 - Train Accuracy:  0.563636\n",
      "epoch:  18  -  cost:  0.694407  - MSE:  0.502529608023 - Train Accuracy:  0.539394\n",
      "epoch:  19  -  cost:  0.694363  - MSE:  0.502276919936 - Train Accuracy:  0.539394\n",
      "epoch:  20  -  cost:  0.694325  - MSE:  0.502066188099 - Train Accuracy:  0.551515\n",
      "epoch:  21  -  cost:  0.694304  - MSE:  0.50206466436 - Train Accuracy:  0.509091\n",
      "epoch:  22  -  cost:  0.694363  - MSE:  0.501451002607 - Train Accuracy:  0.563636\n",
      "epoch:  23  -  cost:  0.694212  - MSE:  0.50164119517 - Train Accuracy:  0.539394\n",
      "epoch:  24  -  cost:  0.694175  - MSE:  0.501457915601 - Train Accuracy:  0.539394\n",
      "epoch:  25  -  cost:  0.69414  - MSE:  0.501292177424 - Train Accuracy:  0.545455\n",
      "epoch:  26  -  cost:  0.69411  - MSE:  0.501202312468 - Train Accuracy:  0.521212\n",
      "epoch:  27  -  cost:  0.69412  - MSE:  0.500874825066 - Train Accuracy:  0.569697\n",
      "epoch:  28  -  cost:  0.694144  - MSE:  0.500986738324 - Train Accuracy:  0.484848\n",
      "epoch:  29  -  cost:  0.694188  - MSE:  0.500461244704 - Train Accuracy:  0.539394\n",
      "epoch:  30  -  cost:  0.694141  - MSE:  0.500382853698 - Train Accuracy:  0.551515\n",
      "epoch:  31  -  cost:  0.694001  - MSE:  0.500353981624 - Train Accuracy:  0.569697\n",
      "epoch:  32  -  cost:  0.694019  - MSE:  0.500377668742 - Train Accuracy:  0.484848\n",
      "epoch:  33  -  cost:  0.694072  - MSE:  0.500029817674 - Train Accuracy:  0.545455\n",
      "epoch:  34  -  cost:  0.693981  - MSE:  0.499957452766 - Train Accuracy:  0.575758\n",
      "epoch:  35  -  cost:  0.693914  - MSE:  0.499942065565 - Train Accuracy:  0.490909\n",
      "epoch:  36  -  cost:  0.693976  - MSE:  0.499721685553 - Train Accuracy:  0.551515\n",
      "epoch:  37  -  cost:  0.693831  - MSE:  0.49964291581 - Train Accuracy:  0.569697\n",
      "epoch:  38  -  cost:  0.693866  - MSE:  0.49954661072 - Train Accuracy:  0.484848\n",
      "epoch:  39  -  cost:  0.693909  - MSE:  0.499415151455 - Train Accuracy:  0.551515\n",
      "epoch:  40  -  cost:  0.693766  - MSE:  0.499312534981 - Train Accuracy:  0.569697\n",
      "epoch:  41  -  cost:  0.693784  - MSE:  0.499164130151 - Train Accuracy:  0.490909\n",
      "epoch:  42  -  cost:  0.693798  - MSE:  0.499116432446 - Train Accuracy:  0.575758\n",
      "epoch:  43  -  cost:  0.693698  - MSE:  0.498928994183 - Train Accuracy:  0.49697\n",
      "epoch:  44  -  cost:  0.693737  - MSE:  0.498921588652 - Train Accuracy:  0.575758\n",
      "epoch:  45  -  cost:  0.693668  - MSE:  0.49869672592 - Train Accuracy:  0.490909\n",
      "epoch:  46  -  cost:  0.693717  - MSE:  0.498747333193 - Train Accuracy:  0.575758\n",
      "epoch:  47  -  cost:  0.693607  - MSE:  0.498488169183 - Train Accuracy:  0.50303\n",
      "epoch:  48  -  cost:  0.693618  - MSE:  0.4985369098 - Train Accuracy:  0.569697\n",
      "epoch:  49  -  cost:  0.693584  - MSE:  0.498269857121 - Train Accuracy:  0.490909\n",
      "epoch:  50  -  cost:  0.69363  - MSE:  0.498400952956 - Train Accuracy:  0.575758\n",
      "epoch:  51  -  cost:  0.693535  - MSE:  0.498077770212 - Train Accuracy:  0.50303\n",
      "epoch:  52  -  cost:  0.693533  - MSE:  0.498185493215 - Train Accuracy:  0.569697\n",
      "epoch:  53  -  cost:  0.693521  - MSE:  0.497866012593 - Train Accuracy:  0.49697\n",
      "epoch:  54  -  cost:  0.693509  - MSE:  0.49803357759 - Train Accuracy:  0.569697\n",
      "epoch:  55  -  cost:  0.693474  - MSE:  0.497690225907 - Train Accuracy:  0.49697\n",
      "epoch:  56  -  cost:  0.693481  - MSE:  0.497885755082 - Train Accuracy:  0.569697\n",
      "epoch:  57  -  cost:  0.693436  - MSE:  0.497520837963 - Train Accuracy:  0.49697\n",
      "epoch:  58  -  cost:  0.69345  - MSE:  0.497740649582 - Train Accuracy:  0.569697\n",
      "epoch:  59  -  cost:  0.693404  - MSE:  0.497355153335 - Train Accuracy:  0.49697\n",
      "epoch:  60  -  cost:  0.693418  - MSE:  0.497597876338 - Train Accuracy:  0.569697\n",
      "epoch:  61  -  cost:  0.693375  - MSE:  0.49719285421 - Train Accuracy:  0.50303\n",
      "epoch:  62  -  cost:  0.693359  - MSE:  0.497414193356 - Train Accuracy:  0.563636\n",
      "epoch:  63  -  cost:  0.693345  - MSE:  0.497038340111 - Train Accuracy:  0.50303\n",
      "epoch:  64  -  cost:  0.69333  - MSE:  0.497275041556 - Train Accuracy:  0.563636\n",
      "epoch:  65  -  cost:  0.693318  - MSE:  0.49688670898 - Train Accuracy:  0.50303\n",
      "epoch:  66  -  cost:  0.6933  - MSE:  0.497133176586 - Train Accuracy:  0.563636\n",
      "epoch:  67  -  cost:  0.693294  - MSE:  0.49673811714 - Train Accuracy:  0.50303\n",
      "epoch:  68  -  cost:  0.69327  - MSE:  0.496992913693 - Train Accuracy:  0.563636\n",
      "epoch:  69  -  cost:  0.693271  - MSE:  0.496592580804 - Train Accuracy:  0.490909\n",
      "epoch:  70  -  cost:  0.693288  - MSE:  0.496988943655 - Train Accuracy:  0.569697\n",
      "epoch:  71  -  cost:  0.693235  - MSE:  0.496499154864 - Train Accuracy:  0.515152\n",
      "epoch:  72  -  cost:  0.693203  - MSE:  0.49662900768 - Train Accuracy:  0.539394\n",
      "epoch:  73  -  cost:  0.693194  - MSE:  0.496491231152 - Train Accuracy:  0.521212\n",
      "epoch:  74  -  cost:  0.693185  - MSE:  0.496565883272 - Train Accuracy:  0.545455\n",
      "epoch:  75  -  cost:  0.693175  - MSE:  0.496353370587 - Train Accuracy:  0.521212\n",
      "epoch:  76  -  cost:  0.69316  - MSE:  0.496427716033 - Train Accuracy:  0.539394\n",
      "epoch:  77  -  cost:  0.69315  - MSE:  0.496286891641 - Train Accuracy:  0.521212\n",
      "epoch:  78  -  cost:  0.693142  - MSE:  0.496366461987 - Train Accuracy:  0.539394\n",
      "epoch:  79  -  cost:  0.693127  - MSE:  0.496218674933 - Train Accuracy:  0.521212\n",
      "epoch:  80  -  cost:  0.693125  - MSE:  0.496302253123 - Train Accuracy:  0.545455\n",
      "epoch:  81  -  cost:  0.693112  - MSE:  0.496079892868 - Train Accuracy:  0.521212\n",
      "epoch:  82  -  cost:  0.693101  - MSE:  0.496162128121 - Train Accuracy:  0.539394\n",
      "epoch:  83  -  cost:  0.69309  - MSE:  0.49601803174 - Train Accuracy:  0.521212\n",
      "epoch:  84  -  cost:  0.693083  - MSE:  0.496103801421 - Train Accuracy:  0.539394\n",
      "epoch:  85  -  cost:  0.69307  - MSE:  0.49595524805 - Train Accuracy:  0.521212\n",
      "epoch:  86  -  cost:  0.693066  - MSE:  0.496043864653 - Train Accuracy:  0.545455\n",
      "epoch:  87  -  cost:  0.693056  - MSE:  0.495820316418 - Train Accuracy:  0.521212\n",
      "epoch:  88  -  cost:  0.693044  - MSE:  0.495907422237 - Train Accuracy:  0.539394\n",
      "epoch:  89  -  cost:  0.693036  - MSE:  0.495765812794 - Train Accuracy:  0.521212\n",
      "epoch:  90  -  cost:  0.693027  - MSE:  0.495855740416 - Train Accuracy:  0.539394\n",
      "epoch:  91  -  cost:  0.693017  - MSE:  0.495710919644 - Train Accuracy:  0.521212\n",
      "epoch:  92  -  cost:  0.693011  - MSE:  0.495803250445 - Train Accuracy:  0.539394\n",
      "epoch:  93  -  cost:  0.692999  - MSE:  0.495656276881 - Train Accuracy:  0.521212\n",
      "epoch:  94  -  cost:  0.692994  - MSE:  0.495750648519 - Train Accuracy:  0.539394\n",
      "epoch:  95  -  cost:  0.692981  - MSE:  0.495602375697 - Train Accuracy:  0.521212\n",
      "epoch:  96  -  cost:  0.692978  - MSE:  0.495698570022 - Train Accuracy:  0.539394\n",
      "epoch:  97  -  cost:  0.692964  - MSE:  0.49554968829 - Train Accuracy:  0.521212\n",
      "epoch:  98  -  cost:  0.692961  - MSE:  0.495647563561 - Train Accuracy:  0.539394\n",
      "epoch:  99  -  cost:  0.692947  - MSE:  0.495498623023 - Train Accuracy:  0.527273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100  -  cost:  0.69294  - MSE:  0.495516498947 - Train Accuracy:  0.539394\n",
      "epoch:  101  -  cost:  0.692934  - MSE:  0.495380949687 - Train Accuracy:  0.521212\n",
      "epoch:  102  -  cost:  0.692925  - MSE:  0.495478242028 - Train Accuracy:  0.539394\n",
      "epoch:  103  -  cost:  0.692917  - MSE:  0.495341205054 - Train Accuracy:  0.521212\n",
      "epoch:  104  -  cost:  0.692909  - MSE:  0.495440596971 - Train Accuracy:  0.539394\n",
      "epoch:  105  -  cost:  0.6929  - MSE:  0.495302701309 - Train Accuracy:  0.527273\n",
      "epoch:  106  -  cost:  0.69289  - MSE:  0.495325798397 - Train Accuracy:  0.533333\n",
      "epoch:  107  -  cost:  0.692883  - MSE:  0.495272871831 - Train Accuracy:  0.527273\n",
      "epoch:  108  -  cost:  0.692874  - MSE:  0.495296666247 - Train Accuracy:  0.533333\n",
      "epoch:  109  -  cost:  0.692866  - MSE:  0.495244204913 - Train Accuracy:  0.527273\n",
      "epoch:  110  -  cost:  0.692858  - MSE:  0.495268862612 - Train Accuracy:  0.533333\n",
      "epoch:  111  -  cost:  0.69285  - MSE:  0.495217050975 - Train Accuracy:  0.527273\n",
      "epoch:  112  -  cost:  0.692843  - MSE:  0.495242694939 - Train Accuracy:  0.539394\n",
      "epoch:  113  -  cost:  0.692836  - MSE:  0.495115194234 - Train Accuracy:  0.521212\n",
      "epoch:  114  -  cost:  0.692827  - MSE:  0.495221856121 - Train Accuracy:  0.539394\n",
      "epoch:  115  -  cost:  0.692819  - MSE:  0.495094412221 - Train Accuracy:  0.521212\n",
      "epoch:  116  -  cost:  0.692812  - MSE:  0.495203140045 - Train Accuracy:  0.539394\n",
      "epoch:  117  -  cost:  0.692802  - MSE:  0.495075389783 - Train Accuracy:  0.521212\n",
      "epoch:  118  -  cost:  0.692797  - MSE:  0.495186195461 - Train Accuracy:  0.539394\n",
      "epoch:  119  -  cost:  0.692785  - MSE:  0.495058485063 - Train Accuracy:  0.521212\n",
      "epoch:  120  -  cost:  0.692782  - MSE:  0.495171301481 - Train Accuracy:  0.539394\n",
      "epoch:  121  -  cost:  0.692768  - MSE:  0.495043870242 - Train Accuracy:  0.527273\n",
      "epoch:  122  -  cost:  0.692761  - MSE:  0.495079549601 - Train Accuracy:  0.539394\n",
      "epoch:  123  -  cost:  0.692756  - MSE:  0.494963886508 - Train Accuracy:  0.515152\n",
      "epoch:  124  -  cost:  0.692752  - MSE:  0.495162514542 - Train Accuracy:  0.545455\n",
      "epoch:  125  -  cost:  0.692739  - MSE:  0.494959496896 - Train Accuracy:  0.515152\n",
      "epoch:  126  -  cost:  0.692738  - MSE:  0.495160086268 - Train Accuracy:  0.545455\n",
      "epoch:  127  -  cost:  0.692721  - MSE:  0.494957204872 - Train Accuracy:  0.515152\n",
      "epoch:  128  -  cost:  0.692723  - MSE:  0.495159665226 - Train Accuracy:  0.545455\n",
      "epoch:  129  -  cost:  0.692703  - MSE:  0.494957155106 - Train Accuracy:  0.521212\n",
      "epoch:  130  -  cost:  0.692699  - MSE:  0.495077828997 - Train Accuracy:  0.545455\n",
      "epoch:  131  -  cost:  0.692692  - MSE:  0.494889351457 - Train Accuracy:  0.521212\n",
      "epoch:  132  -  cost:  0.692677  - MSE:  0.495012227603 - Train Accuracy:  0.539394\n",
      "epoch:  133  -  cost:  0.692672  - MSE:  0.494908065381 - Train Accuracy:  0.521212\n",
      "epoch:  134  -  cost:  0.692662  - MSE:  0.495031640324 - Train Accuracy:  0.545455\n",
      "epoch:  135  -  cost:  0.692658  - MSE:  0.494853508098 - Train Accuracy:  0.521212\n",
      "epoch:  136  -  cost:  0.692641  - MSE:  0.494980502992 - Train Accuracy:  0.539394\n",
      "epoch:  137  -  cost:  0.692637  - MSE:  0.494883292093 - Train Accuracy:  0.521212\n",
      "epoch:  138  -  cost:  0.692625  - MSE:  0.495010055865 - Train Accuracy:  0.539394\n",
      "epoch:  139  -  cost:  0.692616  - MSE:  0.49491273311 - Train Accuracy:  0.521212\n",
      "epoch:  140  -  cost:  0.692611  - MSE:  0.495042395659 - Train Accuracy:  0.551515\n",
      "epoch:  141  -  cost:  0.692608  - MSE:  0.494799688659 - Train Accuracy:  0.521212\n",
      "epoch:  142  -  cost:  0.692586  - MSE:  0.494933533836 - Train Accuracy:  0.515152\n",
      "epoch:  143  -  cost:  0.6926  - MSE:  0.495147695853 - Train Accuracy:  0.551515\n",
      "epoch:  144  -  cost:  0.692572  - MSE:  0.494891067461 - Train Accuracy:  0.521212\n",
      "epoch:  145  -  cost:  0.692562  - MSE:  0.495023771457 - Train Accuracy:  0.551515\n",
      "epoch:  146  -  cost:  0.692563  - MSE:  0.49479664669 - Train Accuracy:  0.521212\n",
      "epoch:  147  -  cost:  0.692539  - MSE:  0.494933584511 - Train Accuracy:  0.521212\n",
      "epoch:  148  -  cost:  0.692539  - MSE:  0.495070457688 - Train Accuracy:  0.551515\n",
      "epoch:  149  -  cost:  0.69253  - MSE:  0.494841796346 - Train Accuracy:  0.521212\n",
      "epoch:  150  -  cost:  0.69251  - MSE:  0.494979831037 - Train Accuracy:  0.539394\n",
      "epoch:  151  -  cost:  0.692504  - MSE:  0.494906991634 - Train Accuracy:  0.521212\n",
      "epoch:  152  -  cost:  0.692493  - MSE:  0.495044841858 - Train Accuracy:  0.551515\n",
      "epoch:  153  -  cost:  0.692492  - MSE:  0.494835323652 - Train Accuracy:  0.521212\n",
      "epoch:  154  -  cost:  0.692468  - MSE:  0.494976118169 - Train Accuracy:  0.533333\n",
      "epoch:  155  -  cost:  0.692457  - MSE:  0.494978154337 - Train Accuracy:  0.521212\n",
      "epoch:  156  -  cost:  0.69246  - MSE:  0.495121308498 - Train Accuracy:  0.551515\n",
      "epoch:  157  -  cost:  0.692446  - MSE:  0.49491115016 - Train Accuracy:  0.521212\n",
      "epoch:  158  -  cost:  0.692427  - MSE:  0.495052270208 - Train Accuracy:  0.539394\n",
      "epoch:  159  -  cost:  0.692416  - MSE:  0.494992450318 - Train Accuracy:  0.521212\n",
      "epoch:  160  -  cost:  0.692414  - MSE:  0.495136872383 - Train Accuracy:  0.551515\n",
      "epoch:  161  -  cost:  0.692402  - MSE:  0.494942457201 - Train Accuracy:  0.527273\n",
      "epoch:  162  -  cost:  0.692382  - MSE:  0.495022436487 - Train Accuracy:  0.521212\n",
      "epoch:  163  -  cost:  0.692381  - MSE:  0.495168578134 - Train Accuracy:  0.551515\n",
      "epoch:  164  -  cost:  0.692367  - MSE:  0.494982372745 - Train Accuracy:  0.527273\n",
      "epoch:  165  -  cost:  0.692346  - MSE:  0.495064193907 - Train Accuracy:  0.521212\n",
      "epoch:  166  -  cost:  0.692348  - MSE:  0.495212239947 - Train Accuracy:  0.557576\n",
      "epoch:  167  -  cost:  0.692336  - MSE:  0.494975757224 - Train Accuracy:  0.521212\n",
      "epoch:  168  -  cost:  0.692309  - MSE:  0.495119902781 - Train Accuracy:  0.533333\n",
      "epoch:  169  -  cost:  0.692297  - MSE:  0.495141257298 - Train Accuracy:  0.539394\n",
      "epoch:  170  -  cost:  0.692289  - MSE:  0.495107175192 - Train Accuracy:  0.521212\n",
      "epoch:  171  -  cost:  0.692284  - MSE:  0.495254148575 - Train Accuracy:  0.551515\n",
      "epoch:  172  -  cost:  0.692269  - MSE:  0.49509723305 - Train Accuracy:  0.527273\n",
      "epoch:  173  -  cost:  0.692247  - MSE:  0.495183535036 - Train Accuracy:  0.533333\n",
      "epoch:  174  -  cost:  0.692233  - MSE:  0.495212291286 - Train Accuracy:  0.533333\n",
      "epoch:  175  -  cost:  0.692221  - MSE:  0.495241189687 - Train Accuracy:  0.545455\n",
      "epoch:  176  -  cost:  0.692216  - MSE:  0.495168284136 - Train Accuracy:  0.527273\n",
      "epoch:  177  -  cost:  0.692193  - MSE:  0.49525565434 - Train Accuracy:  0.533333\n",
      "epoch:  178  -  cost:  0.69218  - MSE:  0.495288778546 - Train Accuracy:  0.545455\n",
      "epoch:  179  -  cost:  0.692175  - MSE:  0.495225412897 - Train Accuracy:  0.527273\n",
      "epoch:  180  -  cost:  0.692152  - MSE:  0.495312989084 - Train Accuracy:  0.539394\n",
      "epoch:  181  -  cost:  0.692141  - MSE:  0.495302534969 - Train Accuracy:  0.527273\n",
      "epoch:  182  -  cost:  0.692128  - MSE:  0.49538823564 - Train Accuracy:  0.545455\n",
      "epoch:  183  -  cost:  0.692113  - MSE:  0.495332458726 - Train Accuracy:  0.527273\n",
      "epoch:  184  -  cost:  0.692097  - MSE:  0.49541783859 - Train Accuracy:  0.545455\n",
      "epoch:  185  -  cost:  0.692084  - MSE:  0.495370381315 - Train Accuracy:  0.527273\n",
      "epoch:  186  -  cost:  0.692067  - MSE:  0.495455347645 - Train Accuracy:  0.545455\n",
      "epoch:  187  -  cost:  0.692053  - MSE:  0.495414677768 - Train Accuracy:  0.527273\n",
      "epoch:  188  -  cost:  0.692036  - MSE:  0.495498540797 - Train Accuracy:  0.545455\n",
      "epoch:  189  -  cost:  0.692021  - MSE:  0.495463912135 - Train Accuracy:  0.527273\n",
      "epoch:  190  -  cost:  0.692005  - MSE:  0.495546111232 - Train Accuracy:  0.545455\n",
      "epoch:  191  -  cost:  0.691987  - MSE:  0.495517090537 - Train Accuracy:  0.527273\n",
      "epoch:  192  -  cost:  0.691973  - MSE:  0.495598877369 - Train Accuracy:  0.545455\n",
      "epoch:  193  -  cost:  0.691951  - MSE:  0.495573328202 - Train Accuracy:  0.527273\n",
      "epoch:  194  -  cost:  0.691942  - MSE:  0.49565531381 - Train Accuracy:  0.551515\n",
      "epoch:  195  -  cost:  0.691924  - MSE:  0.495602664659 - Train Accuracy:  0.527273\n",
      "epoch:  196  -  cost:  0.691902  - MSE:  0.495677617958 - Train Accuracy:  0.545455\n",
      "epoch:  197  -  cost:  0.691884  - MSE:  0.495668780647 - Train Accuracy:  0.527273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  198  -  cost:  0.691871  - MSE:  0.495743795104 - Train Accuracy:  0.551515\n",
      "epoch:  199  -  cost:  0.691852  - MSE:  0.495711739499 - Train Accuracy:  0.527273\n",
      "epoch:  200  -  cost:  0.691831  - MSE:  0.495778727619 - Train Accuracy:  0.545455\n",
      "epoch:  201  -  cost:  0.691808  - MSE:  0.495781416397 - Train Accuracy:  0.527273\n",
      "epoch:  202  -  cost:  0.691802  - MSE:  0.495852017693 - Train Accuracy:  0.557576\n",
      "epoch:  203  -  cost:  0.691785  - MSE:  0.495819744637 - Train Accuracy:  0.527273\n",
      "epoch:  204  -  cost:  0.691753  - MSE:  0.495874434731 - Train Accuracy:  0.545455\n",
      "epoch:  205  -  cost:  0.691733  - MSE:  0.495890079624 - Train Accuracy:  0.527273\n",
      "epoch:  206  -  cost:  0.691722  - MSE:  0.495947567529 - Train Accuracy:  0.557576\n",
      "epoch:  207  -  cost:  0.691706  - MSE:  0.495944531222 - Train Accuracy:  0.527273\n",
      "epoch:  208  -  cost:  0.691673  - MSE:  0.495984561328 - Train Accuracy:  0.545455\n",
      "epoch:  209  -  cost:  0.691648  - MSE:  0.496010348692 - Train Accuracy:  0.533333\n",
      "epoch:  210  -  cost:  0.691631  - MSE:  0.496043538287 - Train Accuracy:  0.551515\n",
      "epoch:  211  -  cost:  0.691616  - MSE:  0.496075527277 - Train Accuracy:  0.527273\n",
      "epoch:  212  -  cost:  0.691592  - MSE:  0.496102158544 - Train Accuracy:  0.551515\n",
      "epoch:  213  -  cost:  0.691567  - MSE:  0.496138994341 - Train Accuracy:  0.527273\n",
      "epoch:  214  -  cost:  0.691554  - MSE:  0.496164017415 - Train Accuracy:  0.557576\n",
      "epoch:  215  -  cost:  0.691531  - MSE:  0.496213887674 - Train Accuracy:  0.527273\n",
      "epoch:  216  -  cost:  0.691501  - MSE:  0.496216121016 - Train Accuracy:  0.557576\n",
      "epoch:  217  -  cost:  0.691489  - MSE:  0.49628887159 - Train Accuracy:  0.533333\n",
      "epoch:  218  -  cost:  0.691446  - MSE:  0.496286498393 - Train Accuracy:  0.545455\n",
      "epoch:  219  -  cost:  0.691424  - MSE:  0.496332632121 - Train Accuracy:  0.527273\n",
      "epoch:  220  -  cost:  0.69142  - MSE:  0.496328896888 - Train Accuracy:  0.557576\n",
      "epoch:  221  -  cost:  0.69138  - MSE:  0.496413333876 - Train Accuracy:  0.533333\n",
      "epoch:  222  -  cost:  0.691349  - MSE:  0.496397614661 - Train Accuracy:  0.545455\n",
      "epoch:  223  -  cost:  0.691321  - MSE:  0.496449623708 - Train Accuracy:  0.545455\n",
      "epoch:  224  -  cost:  0.691295  - MSE:  0.496500571377 - Train Accuracy:  0.539394\n",
      "epoch:  225  -  cost:  0.69127  - MSE:  0.496512601729 - Train Accuracy:  0.545455\n",
      "epoch:  226  -  cost:  0.691242  - MSE:  0.496565153768 - Train Accuracy:  0.545455\n",
      "epoch:  227  -  cost:  0.691214  - MSE:  0.496615408207 - Train Accuracy:  0.539394\n",
      "epoch:  228  -  cost:  0.691187  - MSE:  0.496612891483 - Train Accuracy:  0.545455\n",
      "epoch:  229  -  cost:  0.691158  - MSE:  0.496665645183 - Train Accuracy:  0.551515\n",
      "epoch:  230  -  cost:  0.691133  - MSE:  0.49676637776 - Train Accuracy:  0.533333\n",
      "epoch:  231  -  cost:  0.691102  - MSE:  0.496685332621 - Train Accuracy:  0.551515\n",
      "epoch:  232  -  cost:  0.691064  - MSE:  0.496799338324 - Train Accuracy:  0.539394\n",
      "epoch:  233  -  cost:  0.691039  - MSE:  0.496773140364 - Train Accuracy:  0.551515\n",
      "epoch:  234  -  cost:  0.691002  - MSE:  0.496886488316 - Train Accuracy:  0.539394\n",
      "epoch:  235  -  cost:  0.690974  - MSE:  0.49684494012 - Train Accuracy:  0.551515\n",
      "epoch:  236  -  cost:  0.690936  - MSE:  0.4969614539 - Train Accuracy:  0.539394\n",
      "epoch:  237  -  cost:  0.690907  - MSE:  0.496906067125 - Train Accuracy:  0.551515\n",
      "epoch:  238  -  cost:  0.690867  - MSE:  0.497026453121 - Train Accuracy:  0.545455\n",
      "epoch:  239  -  cost:  0.690833  - MSE:  0.497044405671 - Train Accuracy:  0.551515\n",
      "epoch:  240  -  cost:  0.690802  - MSE:  0.497155216367 - Train Accuracy:  0.539394\n",
      "epoch:  241  -  cost:  0.690766  - MSE:  0.497056175497 - Train Accuracy:  0.551515\n",
      "epoch:  242  -  cost:  0.690725  - MSE:  0.497177117133 - Train Accuracy:  0.545455\n",
      "epoch:  243  -  cost:  0.69069  - MSE:  0.497175808166 - Train Accuracy:  0.551515\n",
      "epoch:  244  -  cost:  0.690652  - MSE:  0.497287188413 - Train Accuracy:  0.539394\n",
      "epoch:  245  -  cost:  0.690624  - MSE:  0.497153728818 - Train Accuracy:  0.569697\n",
      "epoch:  246  -  cost:  0.690647  - MSE:  0.497656327208 - Train Accuracy:  0.515152\n",
      "epoch:  247  -  cost:  0.690635  - MSE:  0.497030547105 - Train Accuracy:  0.575758\n",
      "epoch:  248  -  cost:  0.690529  - MSE:  0.497629525771 - Train Accuracy:  0.521212\n",
      "epoch:  249  -  cost:  0.690552  - MSE:  0.497099163406 - Train Accuracy:  0.575758\n",
      "epoch:  250  -  cost:  0.690454  - MSE:  0.49774096916 - Train Accuracy:  0.521212\n",
      "epoch:  251  -  cost:  0.690476  - MSE:  0.497150267595 - Train Accuracy:  0.575758\n",
      "epoch:  252  -  cost:  0.690367  - MSE:  0.497825772072 - Train Accuracy:  0.527273\n",
      "epoch:  253  -  cost:  0.690357  - MSE:  0.497273924984 - Train Accuracy:  0.569697\n",
      "epoch:  254  -  cost:  0.690267  - MSE:  0.497850013123 - Train Accuracy:  0.539394\n",
      "epoch:  255  -  cost:  0.690218  - MSE:  0.497519865003 - Train Accuracy:  0.563636\n",
      "epoch:  256  -  cost:  0.690182  - MSE:  0.497965835483 - Train Accuracy:  0.539394\n",
      "epoch:  257  -  cost:  0.690129  - MSE:  0.497587477497 - Train Accuracy:  0.563636\n",
      "epoch:  258  -  cost:  0.690089  - MSE:  0.498044476196 - Train Accuracy:  0.539394\n",
      "epoch:  259  -  cost:  0.69004  - MSE:  0.497630918982 - Train Accuracy:  0.563636\n",
      "epoch:  260  -  cost:  0.68999  - MSE:  0.498099238397 - Train Accuracy:  0.539394\n",
      "epoch:  261  -  cost:  0.689953  - MSE:  0.497659192078 - Train Accuracy:  0.569697\n",
      "epoch:  262  -  cost:  0.689917  - MSE:  0.498360419557 - Train Accuracy:  0.527273\n",
      "epoch:  263  -  cost:  0.68994  - MSE:  0.497504401338 - Train Accuracy:  0.587879\n",
      "epoch:  264  -  cost:  0.689957  - MSE:  0.498901908314 - Train Accuracy:  0.50303\n",
      "epoch:  265  -  cost:  0.690137  - MSE:  0.497270871341 - Train Accuracy:  0.606061\n",
      "epoch:  266  -  cost:  0.689962  - MSE:  0.499237521285 - Train Accuracy:  0.49697\n",
      "epoch:  267  -  cost:  0.69014  - MSE:  0.497253350612 - Train Accuracy:  0.612121\n",
      "epoch:  268  -  cost:  0.689943  - MSE:  0.499514351231 - Train Accuracy:  0.49697\n",
      "epoch:  269  -  cost:  0.69003  - MSE:  0.497280001105 - Train Accuracy:  0.618182\n",
      "epoch:  270  -  cost:  0.69001  - MSE:  0.499987986356 - Train Accuracy:  0.49697\n",
      "epoch:  271  -  cost:  0.689848  - MSE:  0.497332753784 - Train Accuracy:  0.630303\n",
      "epoch:  272  -  cost:  0.690298  - MSE:  0.501005415201 - Train Accuracy:  0.490909\n",
      "epoch:  273  -  cost:  0.689694  - MSE:  0.497357431112 - Train Accuracy:  0.606061\n",
      "epoch:  274  -  cost:  0.689635  - MSE:  0.4997519151 - Train Accuracy:  0.49697\n",
      "epoch:  275  -  cost:  0.689845  - MSE:  0.497243754791 - Train Accuracy:  0.612121\n",
      "epoch:  276  -  cost:  0.689508  - MSE:  0.499822788022 - Train Accuracy:  0.49697\n",
      "epoch:  277  -  cost:  0.68979  - MSE:  0.497237441736 - Train Accuracy:  0.612121\n",
      "epoch:  278  -  cost:  0.689368  - MSE:  0.499872103557 - Train Accuracy:  0.49697\n",
      "epoch:  279  -  cost:  0.689739  - MSE:  0.497224590188 - Train Accuracy:  0.612121\n",
      "epoch:  280  -  cost:  0.689219  - MSE:  0.499910051155 - Train Accuracy:  0.49697\n",
      "epoch:  281  -  cost:  0.689689  - MSE:  0.497205717932 - Train Accuracy:  0.612121\n",
      "epoch:  282  -  cost:  0.689063  - MSE:  0.499941925943 - Train Accuracy:  0.49697\n",
      "epoch:  283  -  cost:  0.689639  - MSE:  0.497180922927 - Train Accuracy:  0.612121\n",
      "epoch:  284  -  cost:  0.688904  - MSE:  0.499970106166 - Train Accuracy:  0.50303\n",
      "epoch:  285  -  cost:  0.689428  - MSE:  0.497238289137 - Train Accuracy:  0.612121\n",
      "epoch:  286  -  cost:  0.68885  - MSE:  0.500299674434 - Train Accuracy:  0.49697\n",
      "epoch:  287  -  cost:  0.68947  - MSE:  0.497147453873 - Train Accuracy:  0.612121\n",
      "epoch:  288  -  cost:  0.688623  - MSE:  0.500144739122 - Train Accuracy:  0.515152\n",
      "epoch:  289  -  cost:  0.688948  - MSE:  0.497423665463 - Train Accuracy:  0.612121\n",
      "epoch:  290  -  cost:  0.688776  - MSE:  0.501072092395 - Train Accuracy:  0.49697\n",
      "epoch:  291  -  cost:  0.689217  - MSE:  0.497139042663 - Train Accuracy:  0.612121\n",
      "epoch:  292  -  cost:  0.688367  - MSE:  0.500446426929 - Train Accuracy:  0.509091\n",
      "epoch:  293  -  cost:  0.688932  - MSE:  0.497252853871 - Train Accuracy:  0.624242\n",
      "epoch:  294  -  cost:  0.688746  - MSE:  0.502003976565 - Train Accuracy:  0.49697\n",
      "epoch:  295  -  cost:  0.688946  - MSE:  0.497122963242 - Train Accuracy:  0.612121\n",
      "epoch:  296  -  cost:  0.688104  - MSE:  0.500744745568 - Train Accuracy:  0.509091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  297  -  cost:  0.688746  - MSE:  0.497173961787 - Train Accuracy:  0.618182\n",
      "epoch:  298  -  cost:  0.688212  - MSE:  0.50162747743 - Train Accuracy:  0.49697\n",
      "epoch:  299  -  cost:  0.688908  - MSE:  0.496917509382 - Train Accuracy:  0.624242\n",
      "epoch:  300  -  cost:  0.688076  - MSE:  0.501803346877 - Train Accuracy:  0.49697\n",
      "epoch:  301  -  cost:  0.688834  - MSE:  0.496861126132 - Train Accuracy:  0.624242\n",
      "epoch:  302  -  cost:  0.687899  - MSE:  0.501878922003 - Train Accuracy:  0.49697\n",
      "epoch:  303  -  cost:  0.688778  - MSE:  0.496790053777 - Train Accuracy:  0.624242\n",
      "epoch:  304  -  cost:  0.687708  - MSE:  0.501927315181 - Train Accuracy:  0.49697\n",
      "epoch:  305  -  cost:  0.688732  - MSE:  0.496733707366 - Train Accuracy:  0.624242\n",
      "epoch:  306  -  cost:  0.687507  - MSE:  0.501954808035 - Train Accuracy:  0.50303\n",
      "epoch:  307  -  cost:  0.688436  - MSE:  0.4967531511 - Train Accuracy:  0.630303\n",
      "epoch:  308  -  cost:  0.687721  - MSE:  0.503182758105 - Train Accuracy:  0.49697\n",
      "epoch:  309  -  cost:  0.688448  - MSE:  0.496644651442 - Train Accuracy:  0.630303\n",
      "epoch:  310  -  cost:  0.687473  - MSE:  0.503088020719 - Train Accuracy:  0.49697\n",
      "epoch:  311  -  cost:  0.688427  - MSE:  0.496551287956 - Train Accuracy:  0.636364\n",
      "epoch:  312  -  cost:  0.687542  - MSE:  0.503905220255 - Train Accuracy:  0.49697\n",
      "epoch:  313  -  cost:  0.688258  - MSE:  0.496493087718 - Train Accuracy:  0.636364\n",
      "epoch:  314  -  cost:  0.687414  - MSE:  0.504162591378 - Train Accuracy:  0.49697\n",
      "epoch:  315  -  cost:  0.688182  - MSE:  0.49640582566 - Train Accuracy:  0.636364\n",
      "epoch:  316  -  cost:  0.687222  - MSE:  0.504238203179 - Train Accuracy:  0.49697\n",
      "epoch:  317  -  cost:  0.688134  - MSE:  0.49631715341 - Train Accuracy:  0.642424\n",
      "epoch:  318  -  cost:  0.687333  - MSE:  0.505256244377 - Train Accuracy:  0.49697\n",
      "epoch:  319  -  cost:  0.687954  - MSE:  0.496236482228 - Train Accuracy:  0.636364\n",
      "epoch:  320  -  cost:  0.68686  - MSE:  0.504490203581 - Train Accuracy:  0.49697\n",
      "epoch:  321  -  cost:  0.688051  - MSE:  0.496153653866 - Train Accuracy:  0.654545\n",
      "epoch:  322  -  cost:  0.687657  - MSE:  0.50757115956 - Train Accuracy:  0.490909\n",
      "epoch:  323  -  cost:  0.687981  - MSE:  0.496045426549 - Train Accuracy:  0.654545\n",
      "epoch:  324  -  cost:  0.687464  - MSE:  0.50760976261 - Train Accuracy:  0.490909\n",
      "epoch:  325  -  cost:  0.687943  - MSE:  0.495934814964 - Train Accuracy:  0.666667\n",
      "epoch:  326  -  cost:  0.688114  - MSE:  0.510034435637 - Train Accuracy:  0.490909\n",
      "epoch:  327  -  cost:  0.687588  - MSE:  0.495797993012 - Train Accuracy:  0.654545\n",
      "epoch:  328  -  cost:  0.687211  - MSE:  0.508023738834 - Train Accuracy:  0.490909\n",
      "epoch:  329  -  cost:  0.687809  - MSE:  0.495711525477 - Train Accuracy:  0.666667\n",
      "epoch:  330  -  cost:  0.68774  - MSE:  0.510138128276 - Train Accuracy:  0.490909\n",
      "epoch:  331  -  cost:  0.687501  - MSE:  0.495549179248 - Train Accuracy:  0.666667\n",
      "epoch:  332  -  cost:  0.687681  - MSE:  0.510531270742 - Train Accuracy:  0.490909\n",
      "epoch:  333  -  cost:  0.687406  - MSE:  0.495417230412 - Train Accuracy:  0.666667\n",
      "epoch:  334  -  cost:  0.687492  - MSE:  0.510568197693 - Train Accuracy:  0.490909\n",
      "epoch:  335  -  cost:  0.687356  - MSE:  0.495288807768 - Train Accuracy:  0.666667\n",
      "epoch:  336  -  cost:  0.687276  - MSE:  0.510543312269 - Train Accuracy:  0.490909\n",
      "epoch:  337  -  cost:  0.687326  - MSE:  0.495159605212 - Train Accuracy:  0.678788\n",
      "epoch:  338  -  cost:  0.688076  - MSE:  0.513381679681 - Train Accuracy:  0.490909\n",
      "epoch:  339  -  cost:  0.686945  - MSE:  0.494964213494 - Train Accuracy:  0.666667\n",
      "epoch:  340  -  cost:  0.686992  - MSE:  0.510856461983 - Train Accuracy:  0.490909\n",
      "epoch:  341  -  cost:  0.687185  - MSE:  0.49485888687 - Train Accuracy:  0.684848\n",
      "epoch:  342  -  cost:  0.688222  - MSE:  0.514918836442 - Train Accuracy:  0.490909\n",
      "epoch:  343  -  cost:  0.686675  - MSE:  0.494640053961 - Train Accuracy:  0.678788\n",
      "epoch:  344  -  cost:  0.687688  - MSE:  0.513911980797 - Train Accuracy:  0.490909\n",
      "epoch:  345  -  cost:  0.686692  - MSE:  0.494481311686 - Train Accuracy:  0.684848\n",
      "epoch:  346  -  cost:  0.68798  - MSE:  0.515261653569 - Train Accuracy:  0.490909\n",
      "epoch:  347  -  cost:  0.686473  - MSE:  0.494292067457 - Train Accuracy:  0.684848\n",
      "epoch:  348  -  cost:  0.687833  - MSE:  0.515357034869 - Train Accuracy:  0.490909\n",
      "epoch:  349  -  cost:  0.686377  - MSE:  0.494111418956 - Train Accuracy:  0.684848\n",
      "epoch:  350  -  cost:  0.687614  - MSE:  0.515269169684 - Train Accuracy:  0.490909\n",
      "epoch:  351  -  cost:  0.686305  - MSE:  0.49393120856 - Train Accuracy:  0.684848\n",
      "epoch:  352  -  cost:  0.687379  - MSE:  0.515164779395 - Train Accuracy:  0.490909\n",
      "epoch:  353  -  cost:  0.686249  - MSE:  0.493750916064 - Train Accuracy:  0.690909\n",
      "epoch:  354  -  cost:  0.68775  - MSE:  0.516758349983 - Train Accuracy:  0.490909\n",
      "epoch:  355  -  cost:  0.686016  - MSE:  0.49354794374 - Train Accuracy:  0.690909\n",
      "epoch:  356  -  cost:  0.687595  - MSE:  0.516847978067 - Train Accuracy:  0.490909\n",
      "epoch:  357  -  cost:  0.685917  - MSE:  0.493353305868 - Train Accuracy:  0.690909\n",
      "epoch:  358  -  cost:  0.687362  - MSE:  0.516744077427 - Train Accuracy:  0.490909\n",
      "epoch:  359  -  cost:  0.685845  - MSE:  0.493169694341 - Train Accuracy:  0.69697\n",
      "epoch:  360  -  cost:  0.687765  - MSE:  0.518411111439 - Train Accuracy:  0.490909\n",
      "epoch:  361  -  cost:  0.685597  - MSE:  0.492941456598 - Train Accuracy:  0.690909\n",
      "epoch:  362  -  cost:  0.686941  - MSE:  0.516656861695 - Train Accuracy:  0.490909\n",
      "epoch:  363  -  cost:  0.685669  - MSE:  0.4927818215 - Train Accuracy:  0.69697\n",
      "epoch:  364  -  cost:  0.687275  - MSE:  0.518189337522 - Train Accuracy:  0.490909\n",
      "epoch:  365  -  cost:  0.685455  - MSE:  0.492556580259 - Train Accuracy:  0.69697\n",
      "epoch:  366  -  cost:  0.687087  - MSE:  0.518235427852 - Train Accuracy:  0.490909\n",
      "epoch:  367  -  cost:  0.685365  - MSE:  0.492351591054 - Train Accuracy:  0.709091\n",
      "epoch:  368  -  cost:  0.68824  - MSE:  0.52195484012 - Train Accuracy:  0.490909\n",
      "epoch:  369  -  cost:  0.684928  - MSE:  0.492068602342 - Train Accuracy:  0.69697\n",
      "epoch:  370  -  cost:  0.686714  - MSE:  0.51822231777 - Train Accuracy:  0.490909\n",
      "epoch:  371  -  cost:  0.685119  - MSE:  0.49190395109 - Train Accuracy:  0.715151\n",
      "epoch:  372  -  cost:  0.68848  - MSE:  0.523646105025 - Train Accuracy:  0.490909\n",
      "epoch:  373  -  cost:  0.684536  - MSE:  0.491607164237 - Train Accuracy:  0.70303\n",
      "epoch:  374  -  cost:  0.686945  - MSE:  0.519878566474 - Train Accuracy:  0.490909\n",
      "epoch:  375  -  cost:  0.684689  - MSE:  0.491412598564 - Train Accuracy:  0.715151\n",
      "epoch:  376  -  cost:  0.688026  - MSE:  0.523400720937 - Train Accuracy:  0.490909\n",
      "epoch:  377  -  cost:  0.68426  - MSE:  0.491136344106 - Train Accuracy:  0.715151\n",
      "epoch:  378  -  cost:  0.687878  - MSE:  0.523451812338 - Train Accuracy:  0.490909\n",
      "epoch:  379  -  cost:  0.684069  - MSE:  0.490895292752 - Train Accuracy:  0.721212\n",
      "epoch:  380  -  cost:  0.688385  - MSE:  0.525276348895 - Train Accuracy:  0.490909\n",
      "epoch:  381  -  cost:  0.683724  - MSE:  0.490643756019 - Train Accuracy:  0.709091\n",
      "epoch:  382  -  cost:  0.686633  - MSE:  0.520968204946 - Train Accuracy:  0.490909\n",
      "epoch:  383  -  cost:  0.683904  - MSE:  0.490428696944 - Train Accuracy:  0.721212\n",
      "epoch:  384  -  cost:  0.687751  - MSE:  0.524630227163 - Train Accuracy:  0.490909\n",
      "epoch:  385  -  cost:  0.683487  - MSE:  0.490161414527 - Train Accuracy:  0.721212\n",
      "epoch:  386  -  cost:  0.687582  - MSE:  0.524661708441 - Train Accuracy:  0.490909\n",
      "epoch:  387  -  cost:  0.683297  - MSE:  0.489909639771 - Train Accuracy:  0.721212\n",
      "epoch:  388  -  cost:  0.687295  - MSE:  0.524403101678 - Train Accuracy:  0.490909\n",
      "epoch:  389  -  cost:  0.683144  - MSE:  0.489656894919 - Train Accuracy:  0.721212\n",
      "epoch:  390  -  cost:  0.686994  - MSE:  0.524150687478 - Train Accuracy:  0.490909\n",
      "epoch:  391  -  cost:  0.683011  - MSE:  0.4894022846 - Train Accuracy:  0.721212\n",
      "epoch:  392  -  cost:  0.686687  - MSE:  0.523926143337 - Train Accuracy:  0.490909\n",
      "epoch:  393  -  cost:  0.682899  - MSE:  0.489145061297 - Train Accuracy:  0.727273\n",
      "epoch:  394  -  cost:  0.687194  - MSE:  0.525918549684 - Train Accuracy:  0.490909\n",
      "epoch:  395  -  cost:  0.682611  - MSE:  0.488882965703 - Train Accuracy:  0.727273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  396  -  cost:  0.686939  - MSE:  0.525796335282 - Train Accuracy:  0.490909\n",
      "epoch:  397  -  cost:  0.682448  - MSE:  0.48861948795 - Train Accuracy:  0.727273\n",
      "epoch:  398  -  cost:  0.686623  - MSE:  0.525547142523 - Train Accuracy:  0.490909\n",
      "epoch:  399  -  cost:  0.682312  - MSE:  0.488353277923 - Train Accuracy:  0.727273\n",
      "epoch:  400  -  cost:  0.686295  - MSE:  0.525318805992 - Train Accuracy:  0.490909\n",
      "epoch:  401  -  cost:  0.682196  - MSE:  0.488083641806 - Train Accuracy:  0.727273\n",
      "epoch:  402  -  cost:  0.685961  - MSE:  0.525119416399 - Train Accuracy:  0.490909\n",
      "epoch:  403  -  cost:  0.682097  - MSE:  0.487815556123 - Train Accuracy:  0.727273\n",
      "epoch:  404  -  cost:  0.68562  - MSE:  0.524947620143 - Train Accuracy:  0.490909\n",
      "epoch:  405  -  cost:  0.682014  - MSE:  0.487550439447 - Train Accuracy:  0.727273\n",
      "epoch:  406  -  cost:  0.685271  - MSE:  0.524801329636 - Train Accuracy:  0.490909\n",
      "epoch:  407  -  cost:  0.681946  - MSE:  0.487282511477 - Train Accuracy:  0.727273\n",
      "epoch:  408  -  cost:  0.684913  - MSE:  0.524678873175 - Train Accuracy:  0.490909\n",
      "epoch:  409  -  cost:  0.681879  - MSE:  0.487011173368 - Train Accuracy:  0.721212\n",
      "epoch:  410  -  cost:  0.683677  - MSE:  0.522248196781 - Train Accuracy:  0.490909\n",
      "epoch:  411  -  cost:  0.681956  - MSE:  0.486792068728 - Train Accuracy:  0.70303\n",
      "epoch:  412  -  cost:  0.680734  - MSE:  0.515323926758 - Train Accuracy:  0.490909\n",
      "epoch:  413  -  cost:  0.682327  - MSE:  0.48670956432 - Train Accuracy:  0.69697\n",
      "epoch:  414  -  cost:  0.679299  - MSE:  0.512881551428 - Train Accuracy:  0.490909\n",
      "epoch:  415  -  cost:  0.682577  - MSE:  0.486934751477 - Train Accuracy:  0.70303\n",
      "epoch:  416  -  cost:  0.679535  - MSE:  0.51525804914 - Train Accuracy:  0.490909\n",
      "epoch:  417  -  cost:  0.682624  - MSE:  0.487192876654 - Train Accuracy:  0.69697\n",
      "epoch:  418  -  cost:  0.67817  - MSE:  0.513065764105 - Train Accuracy:  0.49697\n",
      "epoch:  419  -  cost:  0.681987  - MSE:  0.486733342558 - Train Accuracy:  0.715151\n",
      "epoch:  420  -  cost:  0.68086  - MSE:  0.522420649815 - Train Accuracy:  0.490909\n",
      "epoch:  421  -  cost:  0.682837  - MSE:  0.487683076465 - Train Accuracy:  0.69697\n",
      "epoch:  422  -  cost:  0.677024  - MSE:  0.512970544991 - Train Accuracy:  0.509091\n",
      "epoch:  423  -  cost:  0.680308  - MSE:  0.485474623019 - Train Accuracy:  0.70303\n",
      "epoch:  424  -  cost:  0.678861  - MSE:  0.520393289522 - Train Accuracy:  0.490909\n",
      "epoch:  425  -  cost:  0.683358  - MSE:  0.488376141115 - Train Accuracy:  0.684848\n",
      "epoch:  426  -  cost:  0.674266  - MSE:  0.508212765677 - Train Accuracy:  0.527273\n",
      "epoch:  427  -  cost:  0.677887  - MSE:  0.484182212219 - Train Accuracy:  0.690909\n",
      "epoch:  428  -  cost:  0.677105  - MSE:  0.519639583813 - Train Accuracy:  0.49697\n",
      "epoch:  429  -  cost:  0.683088  - MSE:  0.488541799094 - Train Accuracy:  0.678788\n",
      "epoch:  430  -  cost:  0.672591  - MSE:  0.50712329257 - Train Accuracy:  0.539394\n",
      "epoch:  431  -  cost:  0.676113  - MSE:  0.483496764124 - Train Accuracy:  0.690909\n",
      "epoch:  432  -  cost:  0.676927  - MSE:  0.523779765498 - Train Accuracy:  0.49697\n",
      "epoch:  433  -  cost:  0.68386  - MSE:  0.489824040118 - Train Accuracy:  0.678788\n",
      "epoch:  434  -  cost:  0.6711  - MSE:  0.506675720569 - Train Accuracy:  0.545455\n",
      "epoch:  435  -  cost:  0.675057  - MSE:  0.482950410922 - Train Accuracy:  0.690909\n",
      "epoch:  436  -  cost:  0.676235  - MSE:  0.526586939525 - Train Accuracy:  0.50303\n",
      "epoch:  437  -  cost:  0.683779  - MSE:  0.489933561933 - Train Accuracy:  0.684848\n",
      "epoch:  438  -  cost:  0.670683  - MSE:  0.510885601465 - Train Accuracy:  0.545455\n",
      "epoch:  439  -  cost:  0.675151  - MSE:  0.482553028514 - Train Accuracy:  0.709091\n",
      "epoch:  440  -  cost:  0.679504  - MSE:  0.54042135627 - Train Accuracy:  0.490909\n",
      "epoch:  441  -  cost:  0.686955  - MSE:  0.492616284319 - Train Accuracy:  0.642424\n",
      "epoch:  442  -  cost:  0.666927  - MSE:  0.487561776305 - Train Accuracy:  0.654545\n",
      "epoch:  443  -  cost:  0.669013  - MSE:  0.511579616313 - Train Accuracy:  0.545455\n",
      "epoch:  444  -  cost:  0.675486  - MSE:  0.482586413148 - Train Accuracy:  0.709091\n",
      "epoch:  445  -  cost:  0.678317  - MSE:  0.543364518113 - Train Accuracy:  0.490909\n",
      "epoch:  446  -  cost:  0.688093  - MSE:  0.493553144649 - Train Accuracy:  0.606061\n",
      "epoch:  447  -  cost:  0.671206  - MSE:  0.481206245998 - Train Accuracy:  0.709091\n",
      "epoch:  448  -  cost:  0.679119  - MSE:  0.548414554277 - Train Accuracy:  0.490909\n",
      "epoch:  449  -  cost:  0.68835  - MSE:  0.493559360519 - Train Accuracy:  0.593939\n",
      "epoch:  450  -  cost:  0.673758  - MSE:  0.481464223924 - Train Accuracy:  0.709091\n",
      "epoch:  451  -  cost:  0.676889  - MSE:  0.544740051111 - Train Accuracy:  0.49697\n",
      "epoch:  452  -  cost:  0.687416  - MSE:  0.492766463175 - Train Accuracy:  0.612121\n",
      "epoch:  453  -  cost:  0.668513  - MSE:  0.480539121263 - Train Accuracy:  0.715151\n",
      "epoch:  454  -  cost:  0.679971  - MSE:  0.556391834004 - Train Accuracy:  0.490909\n",
      "epoch:  455  -  cost:  0.688567  - MSE:  0.493529739785 - Train Accuracy:  0.587879\n",
      "epoch:  456  -  cost:  0.675372  - MSE:  0.483025806704 - Train Accuracy:  0.709091\n",
      "epoch:  457  -  cost:  0.673676  - MSE:  0.541117856374 - Train Accuracy:  0.509091\n",
      "epoch:  458  -  cost:  0.685296  - MSE:  0.490823210284 - Train Accuracy:  0.648485\n",
      "epoch:  459  -  cost:  0.661569  - MSE:  0.48746447362 - Train Accuracy:  0.648485\n",
      "epoch:  460  -  cost:  0.662  - MSE:  0.504662961726 - Train Accuracy:  0.581818\n",
      "epoch:  461  -  cost:  0.665838  - MSE:  0.479061954688 - Train Accuracy:  0.715151\n",
      "epoch:  462  -  cost:  0.678755  - MSE:  0.563874659484 - Train Accuracy:  0.49697\n",
      "epoch:  463  -  cost:  0.689369  - MSE:  0.493966506875 - Train Accuracy:  0.593939\n",
      "epoch:  464  -  cost:  0.674243  - MSE:  0.482491375657 - Train Accuracy:  0.721212\n",
      "epoch:  465  -  cost:  0.676047  - MSE:  0.558813995603 - Train Accuracy:  0.50303\n",
      "epoch:  466  -  cost:  0.688054  - MSE:  0.493126340806 - Train Accuracy:  0.6\n",
      "epoch:  467  -  cost:  0.670315  - MSE:  0.479646744991 - Train Accuracy:  0.721212\n",
      "epoch:  468  -  cost:  0.676349  - MSE:  0.562752251649 - Train Accuracy:  0.50303\n",
      "epoch:  469  -  cost:  0.688092  - MSE:  0.493108653575 - Train Accuracy:  0.587879\n",
      "epoch:  470  -  cost:  0.673646  - MSE:  0.482122765217 - Train Accuracy:  0.727273\n",
      "epoch:  471  -  cost:  0.675541  - MSE:  0.563283621433 - Train Accuracy:  0.509091\n",
      "epoch:  472  -  cost:  0.687084  - MSE:  0.491964968954 - Train Accuracy:  0.6\n",
      "epoch:  473  -  cost:  0.668769  - MSE:  0.478735142872 - Train Accuracy:  0.721212\n",
      "epoch:  474  -  cost:  0.673836  - MSE:  0.561786822261 - Train Accuracy:  0.515152\n",
      "epoch:  475  -  cost:  0.686009  - MSE:  0.490603329659 - Train Accuracy:  0.6\n",
      "epoch:  476  -  cost:  0.666939  - MSE:  0.477555070299 - Train Accuracy:  0.727273\n",
      "epoch:  477  -  cost:  0.675636  - MSE:  0.570333459829 - Train Accuracy:  0.509091\n",
      "epoch:  478  -  cost:  0.687283  - MSE:  0.492009772425 - Train Accuracy:  0.593939\n",
      "epoch:  479  -  cost:  0.670652  - MSE:  0.480147968581 - Train Accuracy:  0.733333\n",
      "epoch:  480  -  cost:  0.674726  - MSE:  0.570842074157 - Train Accuracy:  0.515152\n",
      "epoch:  481  -  cost:  0.686113  - MSE:  0.4906704715 - Train Accuracy:  0.612121\n",
      "epoch:  482  -  cost:  0.664049  - MSE:  0.476000544725 - Train Accuracy:  0.721212\n",
      "epoch:  483  -  cost:  0.67096  - MSE:  0.56386774786 - Train Accuracy:  0.521212\n",
      "epoch:  484  -  cost:  0.684638  - MSE:  0.489035240624 - Train Accuracy:  0.6\n",
      "epoch:  485  -  cost:  0.664798  - MSE:  0.476520355706 - Train Accuracy:  0.727273\n",
      "epoch:  486  -  cost:  0.67182  - MSE:  0.570551311807 - Train Accuracy:  0.521212\n",
      "epoch:  487  -  cost:  0.685097  - MSE:  0.489455527444 - Train Accuracy:  0.618182\n",
      "epoch:  488  -  cost:  0.660564  - MSE:  0.474745443004 - Train Accuracy:  0.715151\n",
      "epoch:  489  -  cost:  0.666847  - MSE:  0.560210072675 - Train Accuracy:  0.527273\n",
      "epoch:  490  -  cost:  0.683472  - MSE:  0.487846796264 - Train Accuracy:  0.606061\n",
      "epoch:  491  -  cost:  0.66103  - MSE:  0.474708560647 - Train Accuracy:  0.715151\n",
      "epoch:  492  -  cost:  0.665504  - MSE:  0.561414996882 - Train Accuracy:  0.533333\n",
      "epoch:  493  -  cost:  0.682825  - MSE:  0.487201556339 - Train Accuracy:  0.606061\n",
      "epoch:  494  -  cost:  0.659702  - MSE:  0.474229499377 - Train Accuracy:  0.721212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  495  -  cost:  0.667179  - MSE:  0.571994093884 - Train Accuracy:  0.527273\n",
      "epoch:  496  -  cost:  0.684893  - MSE:  0.488796615313 - Train Accuracy:  0.612121\n",
      "epoch:  497  -  cost:  0.660363  - MSE:  0.474554456727 - Train Accuracy:  0.727273\n",
      "epoch:  498  -  cost:  0.668218  - MSE:  0.580134332031 - Train Accuracy:  0.527273\n",
      "epoch:  499  -  cost:  0.685467  - MSE:  0.489187442431 - Train Accuracy:  0.606061\n",
      "epoch:  500  -  cost:  0.663188  - MSE:  0.476109807302 - Train Accuracy:  0.739394\n",
      "epoch:  501  -  cost:  0.67144  - MSE:  0.594127737751 - Train Accuracy:  0.527273\n",
      "epoch:  502  -  cost:  0.686027  - MSE:  0.489723930497 - Train Accuracy:  0.581818\n",
      "epoch:  503  -  cost:  0.672865  - MSE:  0.480838477743 - Train Accuracy:  0.715151\n",
      "epoch:  504  -  cost:  0.655036  - MSE:  0.544896012968 - Train Accuracy:  0.557576\n",
      "epoch:  505  -  cost:  0.675069  - MSE:  0.482013270896 - Train Accuracy:  0.69697\n",
      "epoch:  506  -  cost:  0.648076  - MSE:  0.52145105043 - Train Accuracy:  0.6\n",
      "epoch:  507  -  cost:  0.656784  - MSE:  0.473357425029 - Train Accuracy:  0.733333\n",
      "epoch:  508  -  cost:  0.667317  - MSE:  0.596144180494 - Train Accuracy:  0.533333\n",
      "epoch:  509  -  cost:  0.685612  - MSE:  0.489045147806 - Train Accuracy:  0.581818\n",
      "epoch:  510  -  cost:  0.672358  - MSE:  0.480215971769 - Train Accuracy:  0.715151\n",
      "epoch:  511  -  cost:  0.651809  - MSE:  0.548612126468 - Train Accuracy:  0.569697\n",
      "epoch:  512  -  cost:  0.672729  - MSE:  0.480298492749 - Train Accuracy:  0.709091\n",
      "epoch:  513  -  cost:  0.648393  - MSE:  0.541036102104 - Train Accuracy:  0.581818\n",
      "epoch:  514  -  cost:  0.667113  - MSE:  0.477488004687 - Train Accuracy:  0.721212\n",
      "epoch:  515  -  cost:  0.654518  - MSE:  0.569054685025 - Train Accuracy:  0.557576\n",
      "epoch:  516  -  cost:  0.67874  - MSE:  0.482615146526 - Train Accuracy:  0.630303\n",
      "epoch:  517  -  cost:  0.645166  - MSE:  0.472700184884 - Train Accuracy:  0.733333\n",
      "epoch:  518  -  cost:  0.663391  - MSE:  0.606433059003 - Train Accuracy:  0.551515\n",
      "epoch:  519  -  cost:  0.683747  - MSE:  0.486428805189 - Train Accuracy:  0.593939\n",
      "epoch:  520  -  cost:  0.664865  - MSE:  0.476234267855 - Train Accuracy:  0.727273\n",
      "epoch:  521  -  cost:  0.654809  - MSE:  0.582992922586 - Train Accuracy:  0.557576\n",
      "epoch:  522  -  cost:  0.679927  - MSE:  0.482736022243 - Train Accuracy:  0.618182\n",
      "epoch:  523  -  cost:  0.649826  - MSE:  0.471713557655 - Train Accuracy:  0.739394\n",
      "epoch:  524  -  cost:  0.663666  - MSE:  0.619487615741 - Train Accuracy:  0.551515\n",
      "epoch:  525  -  cost:  0.684042  - MSE:  0.486811669721 - Train Accuracy:  0.587879\n",
      "epoch:  526  -  cost:  0.668761  - MSE:  0.477652191649 - Train Accuracy:  0.709091\n",
      "epoch:  527  -  cost:  0.641565  - MSE:  0.546690454436 - Train Accuracy:  0.6\n",
      "epoch:  528  -  cost:  0.660662  - MSE:  0.474325980522 - Train Accuracy:  0.727273\n",
      "epoch:  529  -  cost:  0.651378  - MSE:  0.590508633367 - Train Accuracy:  0.557576\n",
      "epoch:  530  -  cost:  0.679996  - MSE:  0.482017635894 - Train Accuracy:  0.606061\n",
      "epoch:  531  -  cost:  0.65478  - MSE:  0.472902255761 - Train Accuracy:  0.733333\n",
      "epoch:  532  -  cost:  0.65473  - MSE:  0.609172400984 - Train Accuracy:  0.563636\n",
      "epoch:  533  -  cost:  0.680415  - MSE:  0.48207209331 - Train Accuracy:  0.606061\n",
      "epoch:  534  -  cost:  0.655795  - MSE:  0.472865468968 - Train Accuracy:  0.727273\n",
      "epoch:  535  -  cost:  0.648712  - MSE:  0.596425569349 - Train Accuracy:  0.575758\n",
      "epoch:  536  -  cost:  0.676046  - MSE:  0.478626024763 - Train Accuracy:  0.630303\n",
      "epoch:  537  -  cost:  0.640353  - MSE:  0.471355026152 - Train Accuracy:  0.751515\n",
      "epoch:  538  -  cost:  0.664662  - MSE:  0.656891227311 - Train Accuracy:  0.551515\n",
      "epoch:  539  -  cost:  0.685391  - MSE:  0.49126317896 - Train Accuracy:  0.575758\n",
      "epoch:  540  -  cost:  0.674697  - MSE:  0.477449094177 - Train Accuracy:  0.630303\n",
      "epoch:  541  -  cost:  0.639243  - MSE:  0.471313511975 - Train Accuracy:  0.751515\n",
      "epoch:  542  -  cost:  0.66167  - MSE:  0.655405070119 - Train Accuracy:  0.551515\n",
      "epoch:  543  -  cost:  0.684543  - MSE:  0.489725637851 - Train Accuracy:  0.575758\n",
      "epoch:  544  -  cost:  0.673666  - MSE:  0.476436128471 - Train Accuracy:  0.630303\n",
      "epoch:  545  -  cost:  0.638345  - MSE:  0.471298672334 - Train Accuracy:  0.745455\n",
      "epoch:  546  -  cost:  0.654435  - MSE:  0.641372137635 - Train Accuracy:  0.563636\n",
      "epoch:  547  -  cost:  0.680815  - MSE:  0.482821159087 - Train Accuracy:  0.593939\n",
      "epoch:  548  -  cost:  0.663013  - MSE:  0.474143867571 - Train Accuracy:  0.684848\n",
      "epoch:  549  -  cost:  0.623873  - MSE:  0.514360623172 - Train Accuracy:  0.678788\n",
      "epoch:  550  -  cost:  0.623341  - MSE:  0.491144727722 - Train Accuracy:  0.715151\n",
      "epoch:  551  -  cost:  0.630316  - MSE:  0.571568265384 - Train Accuracy:  0.612121\n",
      "epoch:  552  -  cost:  0.659014  - MSE:  0.472562957521 - Train Accuracy:  0.69697\n",
      "epoch:  553  -  cost:  0.623376  - MSE:  0.546574277788 - Train Accuracy:  0.642424\n",
      "epoch:  554  -  cost:  0.639157  - MSE:  0.471254991844 - Train Accuracy:  0.751515\n",
      "epoch:  555  -  cost:  0.65998  - MSE:  0.695938130198 - Train Accuracy:  0.569697\n",
      "epoch:  556  -  cost:  0.684771  - MSE:  0.492347558536 - Train Accuracy:  0.551515\n",
      "epoch:  557  -  cost:  0.678963  - MSE:  0.481264784284 - Train Accuracy:  0.587879\n",
      "epoch:  558  -  cost:  0.661702  - MSE:  0.47214920792 - Train Accuracy:  0.678788\n",
      "epoch:  559  -  cost:  0.617258  - MSE:  0.511677165781 - Train Accuracy:  0.69697\n",
      "epoch:  560  -  cost:  0.616141  - MSE:  0.512947566878 - Train Accuracy:  0.684848\n",
      "epoch:  561  -  cost:  0.6153  - MSE:  0.504862493678 - Train Accuracy:  0.715151\n",
      "epoch:  562  -  cost:  0.617259  - MSE:  0.552761422425 - Train Accuracy:  0.660606\n",
      "epoch:  563  -  cost:  0.628394  - MSE:  0.473719538183 - Train Accuracy:  0.745455\n",
      "epoch:  564  -  cost:  0.651144  - MSE:  0.705681413965 - Train Accuracy:  0.581818\n",
      "epoch:  565  -  cost:  0.684293  - MSE:  0.493311680932 - Train Accuracy:  0.551515\n",
      "epoch:  566  -  cost:  0.678287  - MSE:  0.481885697736 - Train Accuracy:  0.593939\n",
      "epoch:  567  -  cost:  0.657037  - MSE:  0.469695473764 - Train Accuracy:  0.690909\n",
      "epoch:  568  -  cost:  0.612834  - MSE:  0.543924489231 - Train Accuracy:  0.672727\n",
      "epoch:  569  -  cost:  0.62167  - MSE:  0.477749105765 - Train Accuracy:  0.751515\n",
      "epoch:  570  -  cost:  0.650447  - MSE:  0.724893536922 - Train Accuracy:  0.575758\n",
      "epoch:  571  -  cost:  0.684959  - MSE:  0.496772411045 - Train Accuracy:  0.545455\n",
      "epoch:  572  -  cost:  0.681469  - MSE:  0.48744414428 - Train Accuracy:  0.587879\n",
      "epoch:  573  -  cost:  0.664078  - MSE:  0.469273248646 - Train Accuracy:  0.654545\n",
      "epoch:  574  -  cost:  0.614582  - MSE:  0.487690668293 - Train Accuracy:  0.733333\n",
      "epoch:  575  -  cost:  0.624465  - MSE:  0.639616116252 - Train Accuracy:  0.630303\n",
      "epoch:  576  -  cost:  0.660467  - MSE:  0.468214122816 - Train Accuracy:  0.660606\n",
      "epoch:  577  -  cost:  0.610741  - MSE:  0.49839317571 - Train Accuracy:  0.727273\n",
      "epoch:  578  -  cost:  0.61503  - MSE:  0.609296807464 - Train Accuracy:  0.654545\n",
      "epoch:  579  -  cost:  0.644634  - MSE:  0.468677493095 - Train Accuracy:  0.69697\n",
      "epoch:  580  -  cost:  0.609037  - MSE:  0.583047733923 - Train Accuracy:  0.666667\n",
      "epoch:  581  -  cost:  0.627828  - MSE:  0.474531192771 - Train Accuracy:  0.739394\n",
      "epoch:  582  -  cost:  0.638882  - MSE:  0.736215724932 - Train Accuracy:  0.606061\n",
      "epoch:  583  -  cost:  0.680528  - MSE:  0.487620700074 - Train Accuracy:  0.581818\n",
      "epoch:  584  -  cost:  0.664123  - MSE:  0.469200535711 - Train Accuracy:  0.630303\n",
      "epoch:  585  -  cost:  0.622443  - MSE:  0.478949956776 - Train Accuracy:  0.739394\n",
      "epoch:  586  -  cost:  0.633647  - MSE:  0.729146182238 - Train Accuracy:  0.624242\n",
      "epoch:  587  -  cost:  0.671906  - MSE:  0.476803997517 - Train Accuracy:  0.606061\n",
      "epoch:  588  -  cost:  0.64381  - MSE:  0.467278406555 - Train Accuracy:  0.690909\n",
      "epoch:  589  -  cost:  0.601954  - MSE:  0.566047177549 - Train Accuracy:  0.709091\n",
      "epoch:  590  -  cost:  0.604305  - MSE:  0.512872512983 - Train Accuracy:  0.733333\n",
      "epoch:  591  -  cost:  0.608205  - MSE:  0.630004135348 - Train Accuracy:  0.660606\n",
      "epoch:  592  -  cost:  0.641412  - MSE:  0.467248849517 - Train Accuracy:  0.690909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  593  -  cost:  0.599957  - MSE:  0.577245132601 - Train Accuracy:  0.709091\n",
      "epoch:  594  -  cost:  0.603421  - MSE:  0.510425892044 - Train Accuracy:  0.721212\n",
      "epoch:  595  -  cost:  0.601116  - MSE:  0.609112412885 - Train Accuracy:  0.69697\n",
      "epoch:  596  -  cost:  0.6115  - MSE:  0.49100431179 - Train Accuracy:  0.745455\n",
      "epoch:  597  -  cost:  0.632591  - MSE:  0.78140350844 - Train Accuracy:  0.624242\n",
      "epoch:  598  -  cost:  0.67698  - MSE:  0.484524232653 - Train Accuracy:  0.587879\n",
      "epoch:  599  -  cost:  0.656294  - MSE:  0.467056702802 - Train Accuracy:  0.648485\n",
      "epoch:  600  -  cost:  0.606767  - MSE:  0.498896771709 - Train Accuracy:  0.733333\n",
      "epoch:  601  -  cost:  0.612427  - MSE:  0.703949184182 - Train Accuracy:  0.648485\n",
      "epoch:  602  -  cost:  0.658587  - MSE:  0.468014966997 - Train Accuracy:  0.630303\n",
      "epoch:  603  -  cost:  0.617462  - MSE:  0.487809671918 - Train Accuracy:  0.751515\n",
      "epoch:  604  -  cost:  0.641557  - MSE:  0.850827837935 - Train Accuracy:  0.618182\n",
      "epoch:  605  -  cost:  0.681278  - MSE:  0.491803508994 - Train Accuracy:  0.557576\n",
      "epoch:  606  -  cost:  0.671772  - MSE:  0.47915011405 - Train Accuracy:  0.6\n",
      "epoch:  607  -  cost:  0.645555  - MSE:  0.465536929441 - Train Accuracy:  0.672727\n",
      "epoch:  608  -  cost:  0.596989  - MSE:  0.538923695196 - Train Accuracy:  0.721212\n",
      "epoch:  609  -  cost:  0.594339  - MSE:  0.600494705385 - Train Accuracy:  0.745455\n",
      "epoch:  610  -  cost:  0.593851  - MSE:  0.591118032791 - Train Accuracy:  0.751515\n",
      "epoch:  611  -  cost:  0.594254  - MSE:  0.621698378109 - Train Accuracy:  0.715151\n",
      "epoch:  612  -  cost:  0.599631  - MSE:  0.515934546599 - Train Accuracy:  0.739394\n",
      "epoch:  613  -  cost:  0.606834  - MSE:  0.728586989832 - Train Accuracy:  0.654545\n",
      "epoch:  614  -  cost:  0.652644  - MSE:  0.4672510022 - Train Accuracy:  0.636364\n",
      "epoch:  615  -  cost:  0.610297  - MSE:  0.499553767157 - Train Accuracy:  0.745455\n",
      "epoch:  616  -  cost:  0.625357  - MSE:  0.832721597739 - Train Accuracy:  0.642424\n",
      "epoch:  617  -  cost:  0.670295  - MSE:  0.479545501904 - Train Accuracy:  0.6\n",
      "epoch:  618  -  cost:  0.643032  - MSE:  0.465662552427 - Train Accuracy:  0.678788\n",
      "epoch:  619  -  cost:  0.592495  - MSE:  0.561354325444 - Train Accuracy:  0.727273\n",
      "epoch:  620  -  cost:  0.590835  - MSE:  0.617912572781 - Train Accuracy:  0.745455\n",
      "epoch:  621  -  cost:  0.590061  - MSE:  0.601153843187 - Train Accuracy:  0.739394\n",
      "epoch:  622  -  cost:  0.589506  - MSE:  0.605660044904 - Train Accuracy:  0.733333\n",
      "epoch:  623  -  cost:  0.589277  - MSE:  0.585879113259 - Train Accuracy:  0.739394\n",
      "epoch:  624  -  cost:  0.588738  - MSE:  0.630259296626 - Train Accuracy:  0.739394\n",
      "epoch:  625  -  cost:  0.588833  - MSE:  0.576403812005 - Train Accuracy:  0.745455\n",
      "epoch:  626  -  cost:  0.590325  - MSE:  0.672263932738 - Train Accuracy:  0.727273\n",
      "epoch:  627  -  cost:  0.595151  - MSE:  0.528342051168 - Train Accuracy:  0.745455\n",
      "epoch:  628  -  cost:  0.605974  - MSE:  0.791419863454 - Train Accuracy:  0.678788\n",
      "epoch:  629  -  cost:  0.651628  - MSE:  0.46908831996 - Train Accuracy:  0.642424\n",
      "epoch:  630  -  cost:  0.603969  - MSE:  0.512666374941 - Train Accuracy:  0.739394\n",
      "epoch:  631  -  cost:  0.610184  - MSE:  0.830158314311 - Train Accuracy:  0.660606\n",
      "epoch:  632  -  cost:  0.663399  - MSE:  0.47501196047 - Train Accuracy:  0.606061\n",
      "epoch:  633  -  cost:  0.631391  - MSE:  0.468728638847 - Train Accuracy:  0.678788\n",
      "epoch:  634  -  cost:  0.586887  - MSE:  0.589570802666 - Train Accuracy:  0.733333\n",
      "epoch:  635  -  cost:  0.58546  - MSE:  0.645197353066 - Train Accuracy:  0.733333\n",
      "epoch:  636  -  cost:  0.586307  - MSE:  0.580778375946 - Train Accuracy:  0.727273\n",
      "epoch:  637  -  cost:  0.584232  - MSE:  0.639361474714 - Train Accuracy:  0.745455\n",
      "epoch:  638  -  cost:  0.58388  - MSE:  0.627135791124 - Train Accuracy:  0.751515\n",
      "epoch:  639  -  cost:  0.583724  - MSE:  0.667916411493 - Train Accuracy:  0.733333\n",
      "epoch:  640  -  cost:  0.585058  - MSE:  0.574305177406 - Train Accuracy:  0.745455\n",
      "epoch:  641  -  cost:  0.588314  - MSE:  0.739194709526 - Train Accuracy:  0.721212\n",
      "epoch:  642  -  cost:  0.61062  - MSE:  0.49862513462 - Train Accuracy:  0.715151\n",
      "epoch:  643  -  cost:  0.587429  - MSE:  0.743620975968 - Train Accuracy:  0.727273\n",
      "epoch:  644  -  cost:  0.606549  - MSE:  0.508294504004 - Train Accuracy:  0.727273\n",
      "epoch:  645  -  cost:  0.596288  - MSE:  0.81585596729 - Train Accuracy:  0.684848\n",
      "epoch:  646  -  cost:  0.642947  - MSE:  0.469142826713 - Train Accuracy:  0.660606\n",
      "epoch:  647  -  cost:  0.588632  - MSE:  0.559567215441 - Train Accuracy:  0.751515\n",
      "epoch:  648  -  cost:  0.601705  - MSE:  0.867800657915 - Train Accuracy:  0.69697\n",
      "epoch:  649  -  cost:  0.645584  - MSE:  0.470117248058 - Train Accuracy:  0.648485\n",
      "epoch:  650  -  cost:  0.596815  - MSE:  0.537507431825 - Train Accuracy:  0.739394\n",
      "epoch:  651  -  cost:  0.599446  - MSE:  0.870225426435 - Train Accuracy:  0.690909\n",
      "epoch:  652  -  cost:  0.64609  - MSE:  0.470759884375 - Train Accuracy:  0.642424\n",
      "epoch:  653  -  cost:  0.601329  - MSE:  0.525914870351 - Train Accuracy:  0.727273\n",
      "epoch:  654  -  cost:  0.588945  - MSE:  0.816073368883 - Train Accuracy:  0.727273\n",
      "epoch:  655  -  cost:  0.61051  - MSE:  0.500057769987 - Train Accuracy:  0.709091\n",
      "epoch:  656  -  cost:  0.58099  - MSE:  0.733674558704 - Train Accuracy:  0.751515\n",
      "epoch:  657  -  cost:  0.580757  - MSE:  0.609390454343 - Train Accuracy:  0.739394\n",
      "epoch:  658  -  cost:  0.579506  - MSE:  0.727038738558 - Train Accuracy:  0.751515\n",
      "epoch:  659  -  cost:  0.579484  - MSE:  0.617220100428 - Train Accuracy:  0.751515\n",
      "epoch:  660  -  cost:  0.581966  - MSE:  0.779911776886 - Train Accuracy:  0.733333\n",
      "epoch:  661  -  cost:  0.599323  - MSE:  0.530163018273 - Train Accuracy:  0.739394\n",
      "epoch:  662  -  cost:  0.599998  - MSE:  0.923749538299 - Train Accuracy:  0.684848\n",
      "epoch:  663  -  cost:  0.652269  - MSE:  0.472941772812 - Train Accuracy:  0.624242\n",
      "epoch:  664  -  cost:  0.61317  - MSE:  0.493131509697 - Train Accuracy:  0.709091\n",
      "epoch:  665  -  cost:  0.577791  - MSE:  0.755032648908 - Train Accuracy:  0.757576\n",
      "epoch:  666  -  cost:  0.577309  - MSE:  0.629093702525 - Train Accuracy:  0.757576\n",
      "epoch:  667  -  cost:  0.582072  - MSE:  0.826754416749 - Train Accuracy:  0.739394\n",
      "epoch:  668  -  cost:  0.601111  - MSE:  0.523447684144 - Train Accuracy:  0.721212\n",
      "epoch:  669  -  cost:  0.579114  - MSE:  0.813209199046 - Train Accuracy:  0.739394\n",
      "epoch:  670  -  cost:  0.596504  - MSE:  0.534182379811 - Train Accuracy:  0.739394\n",
      "epoch:  671  -  cost:  0.593554  - MSE:  0.941050027905 - Train Accuracy:  0.69697\n",
      "epoch:  672  -  cost:  0.647838  - MSE:  0.465636687689 - Train Accuracy:  0.630303\n",
      "epoch:  673  -  cost:  0.601185  - MSE:  0.515648366394 - Train Accuracy:  0.709091\n",
      "epoch:  674  -  cost:  0.571996  - MSE:  0.788651548105 - Train Accuracy:  0.763636\n",
      "epoch:  675  -  cost:  0.573942  - MSE:  0.61947550751 - Train Accuracy:  0.769697\n",
      "epoch:  676  -  cost:  0.591349  - MSE:  0.968587462564 - Train Accuracy:  0.690909\n",
      "epoch:  677  -  cost:  0.66052  - MSE:  0.457229868922 - Train Accuracy:  0.618182\n",
      "epoch:  678  -  cost:  0.608321  - MSE:  0.501642243478 - Train Accuracy:  0.69697\n",
      "epoch:  679  -  cost:  0.571564  - MSE:  0.737937642114 - Train Accuracy:  0.757576\n",
      "epoch:  680  -  cost:  0.569586  - MSE:  0.699195204636 - Train Accuracy:  0.751515\n",
      "epoch:  681  -  cost:  0.567893  - MSE:  0.724766555805 - Train Accuracy:  0.763636\n",
      "epoch:  682  -  cost:  0.566488  - MSE:  0.754316601441 - Train Accuracy:  0.769697\n",
      "epoch:  683  -  cost:  0.564152  - MSE:  0.73411828895 - Train Accuracy:  0.781818\n",
      "epoch:  684  -  cost:  0.56498  - MSE:  0.820736507036 - Train Accuracy:  0.745455\n",
      "epoch:  685  -  cost:  0.599252  - MSE:  0.508073770035 - Train Accuracy:  0.715151\n",
      "epoch:  686  -  cost:  0.601145  - MSE:  1.07116501964 - Train Accuracy:  0.660606\n",
      "epoch:  687  -  cost:  0.697869  - MSE:  0.463751802307 - Train Accuracy:  0.569697\n",
      "epoch:  688  -  cost:  0.641031  - MSE:  0.472850118485 - Train Accuracy:  0.642424\n",
      "epoch:  689  -  cost:  0.596351  - MSE:  0.534374196759 - Train Accuracy:  0.715151\n",
      "epoch:  690  -  cost:  0.568363  - MSE:  0.798325696619 - Train Accuracy:  0.775758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  691  -  cost:  0.566144  - MSE:  0.712777022294 - Train Accuracy:  0.757576\n",
      "epoch:  692  -  cost:  0.563836  - MSE:  0.770230315477 - Train Accuracy:  0.769697\n",
      "epoch:  693  -  cost:  0.562009  - MSE:  0.750066085487 - Train Accuracy:  0.763636\n",
      "epoch:  694  -  cost:  0.560218  - MSE:  0.74503331202 - Train Accuracy:  0.781818\n",
      "epoch:  695  -  cost:  0.558766  - MSE:  0.811461584846 - Train Accuracy:  0.769697\n",
      "epoch:  696  -  cost:  0.564986  - MSE:  0.630698403005 - Train Accuracy:  0.769697\n",
      "epoch:  697  -  cost:  0.608391  - MSE:  1.15808925947 - Train Accuracy:  0.666667\n",
      "epoch:  698  -  cost:  0.717423  - MSE:  0.450687318091 - Train Accuracy:  0.545455\n",
      "epoch:  699  -  cost:  0.665816  - MSE:  0.484919013212 - Train Accuracy:  0.593939\n",
      "epoch:  700  -  cost:  0.635624  - MSE:  0.471794987913 - Train Accuracy:  0.654545\n",
      "epoch:  701  -  cost:  0.58639  - MSE:  0.567216962309 - Train Accuracy:  0.739394\n",
      "epoch:  702  -  cost:  0.573193  - MSE:  0.965039665229 - Train Accuracy:  0.715151\n",
      "epoch:  703  -  cost:  0.623211  - MSE:  0.470889801829 - Train Accuracy:  0.672727\n",
      "epoch:  704  -  cost:  0.572174  - MSE:  0.629714388213 - Train Accuracy:  0.769697\n",
      "epoch:  705  -  cost:  0.588992  - MSE:  1.10403576444 - Train Accuracy:  0.690909\n",
      "epoch:  706  -  cost:  0.659349  - MSE:  0.466623809571 - Train Accuracy:  0.612121\n",
      "epoch:  707  -  cost:  0.61807  - MSE:  0.47975402726 - Train Accuracy:  0.678788\n",
      "epoch:  708  -  cost:  0.569286  - MSE:  0.653428063135 - Train Accuracy:  0.769697\n",
      "epoch:  709  -  cost:  0.578423  - MSE:  1.06296878276 - Train Accuracy:  0.709091\n",
      "epoch:  710  -  cost:  0.644294  - MSE:  0.463066157095 - Train Accuracy:  0.624242\n",
      "epoch:  711  -  cost:  0.602552  - MSE:  0.507548665222 - Train Accuracy:  0.690909\n",
      "epoch:  712  -  cost:  0.560599  - MSE:  0.741425627945 - Train Accuracy:  0.769697\n",
      "epoch:  713  -  cost:  0.558745  - MSE:  0.850951108316 - Train Accuracy:  0.763636\n",
      "epoch:  714  -  cost:  0.558869  - MSE:  0.715714757662 - Train Accuracy:  0.775758\n",
      "epoch:  715  -  cost:  0.565538  - MSE:  1.01489050836 - Train Accuracy:  0.733333\n",
      "epoch:  716  -  cost:  0.626666  - MSE:  0.461945045019 - Train Accuracy:  0.678788\n",
      "epoch:  717  -  cost:  0.564841  - MSE:  0.680176076831 - Train Accuracy:  0.781818\n",
      "epoch:  718  -  cost:  0.578293  - MSE:  1.11312194949 - Train Accuracy:  0.70303\n",
      "epoch:  719  -  cost:  0.646543  - MSE:  0.465638074896 - Train Accuracy:  0.624242\n",
      "epoch:  720  -  cost:  0.605913  - MSE:  0.492494751654 - Train Accuracy:  0.684848\n",
      "epoch:  721  -  cost:  0.563864  - MSE:  0.68875973681 - Train Accuracy:  0.775758\n",
      "epoch:  722  -  cost:  0.585755  - MSE:  1.19330007546 - Train Accuracy:  0.69697\n",
      "epoch:  723  -  cost:  0.663142  - MSE:  0.46669296644 - Train Accuracy:  0.606061\n",
      "epoch:  724  -  cost:  0.621956  - MSE:  0.475728994284 - Train Accuracy:  0.672727\n",
      "epoch:  725  -  cost:  0.572635  - MSE:  0.635611272795 - Train Accuracy:  0.757576\n",
      "epoch:  726  -  cost:  0.567875  - MSE:  1.09555170147 - Train Accuracy:  0.739394\n",
      "epoch:  727  -  cost:  0.615885  - MSE:  0.475056390052 - Train Accuracy:  0.672727\n",
      "epoch:  728  -  cost:  0.571397  - MSE:  0.638857923664 - Train Accuracy:  0.757576\n",
      "epoch:  729  -  cost:  0.566323  - MSE:  1.108570028 - Train Accuracy:  0.733333\n",
      "epoch:  730  -  cost:  0.61734  - MSE:  0.471923877377 - Train Accuracy:  0.672727\n",
      "epoch:  731  -  cost:  0.570767  - MSE:  0.646320170606 - Train Accuracy:  0.757576\n",
      "epoch:  732  -  cost:  0.564041  - MSE:  1.10456810127 - Train Accuracy:  0.745455\n",
      "epoch:  733  -  cost:  0.60788  - MSE:  0.486217938885 - Train Accuracy:  0.690909\n",
      "epoch:  734  -  cost:  0.559948  - MSE:  0.724731465134 - Train Accuracy:  0.775758\n",
      "epoch:  735  -  cost:  0.572494  - MSE:  1.19473827345 - Train Accuracy:  0.721212\n",
      "epoch:  736  -  cost:  0.641323  - MSE:  0.460626827532 - Train Accuracy:  0.636364\n",
      "epoch:  737  -  cost:  0.592641  - MSE:  0.544119022611 - Train Accuracy:  0.70303\n",
      "epoch:  738  -  cost:  0.554825  - MSE:  0.828228249994 - Train Accuracy:  0.775758\n",
      "epoch:  739  -  cost:  0.552739  - MSE:  0.892901293168 - Train Accuracy:  0.787879\n",
      "epoch:  740  -  cost:  0.550946  - MSE:  0.871472821839 - Train Accuracy:  0.787879\n",
      "epoch:  741  -  cost:  0.549197  - MSE:  0.900866982688 - Train Accuracy:  0.781818\n",
      "epoch:  742  -  cost:  0.549781  - MSE:  0.798867503139 - Train Accuracy:  0.763636\n",
      "epoch:  743  -  cost:  0.547851  - MSE:  0.907729060518 - Train Accuracy:  0.787879\n",
      "epoch:  744  -  cost:  0.547469  - MSE:  0.829705190485 - Train Accuracy:  0.781818\n",
      "epoch:  745  -  cost:  0.549133  - MSE:  1.05088605833 - Train Accuracy:  0.781818\n",
      "epoch:  746  -  cost:  0.575945  - MSE:  0.591463087164 - Train Accuracy:  0.745455\n",
      "epoch:  747  -  cost:  0.586303  - MSE:  1.3226808474 - Train Accuracy:  0.690909\n",
      "epoch:  748  -  cost:  0.668595  - MSE:  0.474291817129 - Train Accuracy:  0.587879\n",
      "epoch:  749  -  cost:  0.631605  - MSE:  0.471322832313 - Train Accuracy:  0.654545\n",
      "epoch:  750  -  cost:  0.582876  - MSE:  0.567065262151 - Train Accuracy:  0.715151\n",
      "epoch:  751  -  cost:  0.548067  - MSE:  0.91264859715 - Train Accuracy:  0.787879\n",
      "epoch:  752  -  cost:  0.546726  - MSE:  0.859524764944 - Train Accuracy:  0.793939\n",
      "epoch:  753  -  cost:  0.545379  - MSE:  1.01365338444 - Train Accuracy:  0.812121\n",
      "epoch:  754  -  cost:  0.544356  - MSE:  0.829305484814 - Train Accuracy:  0.787879\n",
      "epoch:  755  -  cost:  0.547092  - MSE:  1.09440132986 - Train Accuracy:  0.775758\n",
      "epoch:  756  -  cost:  0.588256  - MSE:  0.534810557663 - Train Accuracy:  0.70303\n",
      "epoch:  757  -  cost:  0.544662  - MSE:  0.938193103238 - Train Accuracy:  0.806061\n",
      "epoch:  758  -  cost:  0.54238  - MSE:  0.949760811025 - Train Accuracy:  0.806061\n",
      "epoch:  759  -  cost:  0.540285  - MSE:  0.912598343629 - Train Accuracy:  0.812121\n",
      "epoch:  760  -  cost:  0.540808  - MSE:  1.0445888749 - Train Accuracy:  0.787879\n",
      "epoch:  761  -  cost:  0.567807  - MSE:  0.618029553772 - Train Accuracy:  0.757576\n",
      "epoch:  762  -  cost:  0.571162  - MSE:  1.29306585894 - Train Accuracy:  0.69697\n",
      "epoch:  763  -  cost:  0.670015  - MSE:  0.469210043042 - Train Accuracy:  0.587879\n",
      "epoch:  764  -  cost:  0.624894  - MSE:  0.475934093271 - Train Accuracy:  0.660606\n",
      "epoch:  765  -  cost:  0.577631  - MSE:  0.591186868717 - Train Accuracy:  0.727273\n",
      "epoch:  766  -  cost:  0.542039  - MSE:  0.961779683384 - Train Accuracy:  0.806061\n",
      "epoch:  767  -  cost:  0.539336  - MSE:  0.951920343895 - Train Accuracy:  0.806061\n",
      "epoch:  768  -  cost:  0.536689  - MSE:  0.964709965132 - Train Accuracy:  0.812121\n",
      "epoch:  769  -  cost:  0.534796  - MSE:  0.984672679464 - Train Accuracy:  0.812121\n",
      "epoch:  770  -  cost:  0.534196  - MSE:  0.931603193781 - Train Accuracy:  0.818182\n",
      "epoch:  771  -  cost:  0.541529  - MSE:  1.12371676614 - Train Accuracy:  0.751515\n",
      "epoch:  772  -  cost:  0.619076  - MSE:  0.465249972316 - Train Accuracy:  0.672727\n",
      "epoch:  773  -  cost:  0.559144  - MSE:  0.684382805124 - Train Accuracy:  0.763636\n",
      "epoch:  774  -  cost:  0.547795  - MSE:  1.19373751062 - Train Accuracy:  0.739394\n",
      "epoch:  775  -  cost:  0.616804  - MSE:  0.469678008254 - Train Accuracy:  0.660606\n",
      "epoch:  776  -  cost:  0.573511  - MSE:  0.595551751282 - Train Accuracy:  0.733333\n",
      "epoch:  777  -  cost:  0.53757  - MSE:  1.11918459394 - Train Accuracy:  0.8\n",
      "epoch:  778  -  cost:  0.558057  - MSE:  0.67432519592 - Train Accuracy:  0.763636\n",
      "epoch:  779  -  cost:  0.544982  - MSE:  1.22450168883 - Train Accuracy:  0.751515\n",
      "epoch:  780  -  cost:  0.615938  - MSE:  0.469062249124 - Train Accuracy:  0.666667\n",
      "epoch:  781  -  cost:  0.567081  - MSE:  0.638218680241 - Train Accuracy:  0.751515\n",
      "epoch:  782  -  cost:  0.54458  - MSE:  1.2304635573 - Train Accuracy:  0.751515\n",
      "epoch:  783  -  cost:  0.605375  - MSE:  0.490541727792 - Train Accuracy:  0.678788\n",
      "epoch:  784  -  cost:  0.558134  - MSE:  0.687886044591 - Train Accuracy:  0.763636\n",
      "epoch:  785  -  cost:  0.551312  - MSE:  1.33190489747 - Train Accuracy:  0.721212\n",
      "epoch:  786  -  cost:  0.63817  - MSE:  0.460314398279 - Train Accuracy:  0.624242\n",
      "epoch:  787  -  cost:  0.595977  - MSE:  0.521115427891 - Train Accuracy:  0.690909\n",
      "epoch:  788  -  cost:  0.551414  - MSE:  0.764721294953 - Train Accuracy:  0.781818\n",
      "epoch:  789  -  cost:  0.582552  - MSE:  1.56800185011 - Train Accuracy:  0.690909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  790  -  cost:  0.677145  - MSE:  0.474174868874 - Train Accuracy:  0.563636\n",
      "epoch:  791  -  cost:  0.65033  - MSE:  0.469826053739 - Train Accuracy:  0.606061\n",
      "epoch:  792  -  cost:  0.606143  - MSE:  0.443663753868 - Train Accuracy:  0.660606\n",
      "epoch:  793  -  cost:  0.547805  - MSE:  0.439008923442 - Train Accuracy:  0.70303\n",
      "epoch:  794  -  cost:  0.487999  - MSE:  0.807922840281 - Train Accuracy:  0.818182\n",
      "epoch:  795  -  cost:  0.463088  - MSE:  0.965385439701 - Train Accuracy:  0.8\n",
      "epoch:  796  -  cost:  0.552938  - MSE:  0.319917428713 - Train Accuracy:  0.690909\n",
      "epoch:  797  -  cost:  0.653978  - MSE:  2.23093096427 - Train Accuracy:  0.666667\n",
      "epoch:  798  -  cost:  0.964648  - MSE:  0.891891381043 - Train Accuracy:  0.509091\n",
      "epoch:  799  -  cost:  0.674476  - MSE:  0.412585558208 - Train Accuracy:  0.509091\n",
      "epoch:  800  -  cost:  0.670203  - MSE:  0.367814233011 - Train Accuracy:  0.509091\n",
      "epoch:  801  -  cost:  0.668036  - MSE:  0.354469125058 - Train Accuracy:  0.509091\n",
      "epoch:  802  -  cost:  0.666023  - MSE:  0.34930285199 - Train Accuracy:  0.509091\n",
      "epoch:  803  -  cost:  0.663895  - MSE:  0.347341264509 - Train Accuracy:  0.509091\n",
      "epoch:  804  -  cost:  0.662082  - MSE:  0.347887202966 - Train Accuracy:  0.509091\n",
      "epoch:  805  -  cost:  0.660295  - MSE:  0.346488314285 - Train Accuracy:  0.509091\n",
      "epoch:  806  -  cost:  0.658123  - MSE:  0.343150408065 - Train Accuracy:  0.509091\n",
      "epoch:  807  -  cost:  0.656158  - MSE:  0.342614372591 - Train Accuracy:  0.509091\n",
      "epoch:  808  -  cost:  0.6541  - MSE:  0.339998623371 - Train Accuracy:  0.509091\n",
      "epoch:  809  -  cost:  0.6519  - MSE:  0.343448424961 - Train Accuracy:  0.509091\n",
      "epoch:  810  -  cost:  0.649926  - MSE:  0.331879862097 - Train Accuracy:  0.509091\n",
      "epoch:  811  -  cost:  0.647572  - MSE:  0.335733588431 - Train Accuracy:  0.509091\n",
      "epoch:  812  -  cost:  0.64541  - MSE:  0.337746787398 - Train Accuracy:  0.509091\n",
      "epoch:  813  -  cost:  0.643254  - MSE:  0.325090389593 - Train Accuracy:  0.509091\n",
      "epoch:  814  -  cost:  0.640923  - MSE:  0.333295843728 - Train Accuracy:  0.509091\n",
      "epoch:  815  -  cost:  0.638917  - MSE:  0.317950012962 - Train Accuracy:  0.509091\n",
      "epoch:  816  -  cost:  0.636885  - MSE:  0.334682757007 - Train Accuracy:  0.509091\n",
      "epoch:  817  -  cost:  0.636612  - MSE:  0.299876573962 - Train Accuracy:  0.509091\n",
      "epoch:  818  -  cost:  0.638988  - MSE:  0.362908656336 - Train Accuracy:  0.509091\n",
      "epoch:  819  -  cost:  0.643041  - MSE:  0.278871514018 - Train Accuracy:  0.509091\n",
      "epoch:  820  -  cost:  0.646365  - MSE:  0.40160092223 - Train Accuracy:  0.509091\n",
      "epoch:  821  -  cost:  0.633584  - MSE:  0.288134653866 - Train Accuracy:  0.509091\n",
      "epoch:  822  -  cost:  0.637858  - MSE:  0.374393476912 - Train Accuracy:  0.509091\n",
      "epoch:  823  -  cost:  0.635833  - MSE:  0.283453496297 - Train Accuracy:  0.509091\n",
      "epoch:  824  -  cost:  0.640398  - MSE:  0.389687276359 - Train Accuracy:  0.509091\n",
      "epoch:  825  -  cost:  0.628229  - MSE:  0.2878339577 - Train Accuracy:  0.509091\n",
      "epoch:  826  -  cost:  0.638952  - MSE:  0.390529823542 - Train Accuracy:  0.509091\n",
      "epoch:  827  -  cost:  0.625103  - MSE:  0.289215706161 - Train Accuracy:  0.509091\n",
      "epoch:  828  -  cost:  0.635971  - MSE:  0.385648105118 - Train Accuracy:  0.509091\n",
      "epoch:  829  -  cost:  0.62405  - MSE:  0.290328650526 - Train Accuracy:  0.509091\n",
      "epoch:  830  -  cost:  0.639779  - MSE:  0.403466212612 - Train Accuracy:  0.509091\n",
      "epoch:  831  -  cost:  0.617127  - MSE:  0.294170584243 - Train Accuracy:  0.509091\n",
      "epoch:  832  -  cost:  0.626245  - MSE:  0.36392651193 - Train Accuracy:  0.509091\n",
      "epoch:  833  -  cost:  0.627436  - MSE:  0.298866822489 - Train Accuracy:  0.509091\n",
      "epoch:  834  -  cost:  0.648181  - MSE:  0.426870493614 - Train Accuracy:  0.509091\n",
      "epoch:  835  -  cost:  0.607572  - MSE:  0.30583364965 - Train Accuracy:  0.509091\n",
      "epoch:  836  -  cost:  0.607495  - MSE:  0.3012979909 - Train Accuracy:  0.509091\n",
      "epoch:  837  -  cost:  0.610214  - MSE:  0.324867282861 - Train Accuracy:  0.509091\n",
      "epoch:  838  -  cost:  0.618871  - MSE:  0.306406135444 - Train Accuracy:  0.509091\n",
      "epoch:  839  -  cost:  0.646859  - MSE:  0.426922746138 - Train Accuracy:  0.509091\n",
      "epoch:  840  -  cost:  0.603007  - MSE:  0.310373262358 - Train Accuracy:  0.509091\n",
      "epoch:  841  -  cost:  0.607332  - MSE:  0.306309267722 - Train Accuracy:  0.509091\n",
      "epoch:  842  -  cost:  0.623134  - MSE:  0.374909238795 - Train Accuracy:  0.509091\n",
      "epoch:  843  -  cost:  0.615287  - MSE:  0.317983061811 - Train Accuracy:  0.509091\n",
      "epoch:  844  -  cost:  0.641872  - MSE:  0.418607782612 - Train Accuracy:  0.509091\n",
      "epoch:  845  -  cost:  0.600095  - MSE:  0.315183659867 - Train Accuracy:  0.509091\n",
      "epoch:  846  -  cost:  0.601487  - MSE:  0.312935039656 - Train Accuracy:  0.509091\n",
      "epoch:  847  -  cost:  0.615844  - MSE:  0.361778215064 - Train Accuracy:  0.509091\n",
      "epoch:  848  -  cost:  0.609565  - MSE:  0.327563536688 - Train Accuracy:  0.509091\n",
      "epoch:  849  -  cost:  0.639158  - MSE:  0.415971199242 - Train Accuracy:  0.509091\n",
      "epoch:  850  -  cost:  0.598279  - MSE:  0.320621854158 - Train Accuracy:  0.509091\n",
      "epoch:  851  -  cost:  0.597013  - MSE:  0.320259481034 - Train Accuracy:  0.509091\n",
      "epoch:  852  -  cost:  0.60624  - MSE:  0.345765758861 - Train Accuracy:  0.509091\n",
      "epoch:  853  -  cost:  0.614767  - MSE:  0.348822015601 - Train Accuracy:  0.509091\n",
      "epoch:  854  -  cost:  0.649516  - MSE:  0.4412786953 - Train Accuracy:  0.50303\n",
      "epoch:  855  -  cost:  0.599044  - MSE:  0.333034862399 - Train Accuracy:  0.509091\n",
      "epoch:  856  -  cost:  0.603051  - MSE:  0.343547326032 - Train Accuracy:  0.509091\n",
      "epoch:  857  -  cost:  0.62738  - MSE:  0.397275363905 - Train Accuracy:  0.509091\n",
      "epoch:  858  -  cost:  0.594445  - MSE:  0.333761473099 - Train Accuracy:  0.509091\n",
      "epoch:  859  -  cost:  0.609925  - MSE:  0.36381849908 - Train Accuracy:  0.509091\n",
      "epoch:  860  -  cost:  0.608537  - MSE:  0.362205628296 - Train Accuracy:  0.509091\n",
      "epoch:  861  -  cost:  0.640477  - MSE:  0.425711966619 - Train Accuracy:  0.509091\n",
      "epoch:  862  -  cost:  0.596626  - MSE:  0.338829071204 - Train Accuracy:  0.509091\n",
      "epoch:  863  -  cost:  0.615884  - MSE:  0.387712628204 - Train Accuracy:  0.509091\n",
      "epoch:  864  -  cost:  0.657352  - MSE:  0.460291279608 - Train Accuracy:  0.509091\n",
      "epoch:  865  -  cost:  0.622601  - MSE:  0.391919436182 - Train Accuracy:  0.509091\n",
      "epoch:  866  -  cost:  0.589869  - MSE:  0.3455586204 - Train Accuracy:  0.509091\n",
      "epoch:  867  -  cost:  0.600995  - MSE:  0.353150556513 - Train Accuracy:  0.509091\n",
      "epoch:  868  -  cost:  0.611743  - MSE:  0.396101444205 - Train Accuracy:  0.509091\n",
      "epoch:  869  -  cost:  0.649421  - MSE:  0.444072696595 - Train Accuracy:  0.509091\n",
      "epoch:  870  -  cost:  0.600543  - MSE:  0.355544605887 - Train Accuracy:  0.509091\n",
      "epoch:  871  -  cost:  0.608626  - MSE:  0.398056940102 - Train Accuracy:  0.509091\n",
      "epoch:  872  -  cost:  0.642245  - MSE:  0.433204979755 - Train Accuracy:  0.509091\n",
      "epoch:  873  -  cost:  0.590998  - MSE:  0.341698722398 - Train Accuracy:  0.509091\n",
      "epoch:  874  -  cost:  0.599484  - MSE:  0.386304547285 - Train Accuracy:  0.509091\n",
      "epoch:  875  -  cost:  0.631903  - MSE:  0.413491925207 - Train Accuracy:  0.509091\n",
      "epoch:  876  -  cost:  0.587236  - MSE:  0.340623101255 - Train Accuracy:  0.509091\n",
      "epoch:  877  -  cost:  0.58731  - MSE:  0.369693926199 - Train Accuracy:  0.509091\n",
      "epoch:  878  -  cost:  0.599912  - MSE:  0.36143352802 - Train Accuracy:  0.509091\n",
      "epoch:  879  -  cost:  0.596425  - MSE:  0.394740360058 - Train Accuracy:  0.509091\n",
      "epoch:  880  -  cost:  0.629962  - MSE:  0.411623441818 - Train Accuracy:  0.509091\n",
      "epoch:  881  -  cost:  0.585363  - MSE:  0.344916303453 - Train Accuracy:  0.509091\n",
      "epoch:  882  -  cost:  0.586949  - MSE:  0.38213817366 - Train Accuracy:  0.509091\n",
      "epoch:  883  -  cost:  0.605339  - MSE:  0.375704566283 - Train Accuracy:  0.509091\n",
      "epoch:  884  -  cost:  0.598207  - MSE:  0.413208053586 - Train Accuracy:  0.509091\n",
      "epoch:  885  -  cost:  0.634825  - MSE:  0.424964690216 - Train Accuracy:  0.509091\n",
      "epoch:  886  -  cost:  0.586517  - MSE:  0.348447177593 - Train Accuracy:  0.509091\n",
      "epoch:  887  -  cost:  0.593764  - MSE:  0.403560067947 - Train Accuracy:  0.509091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  888  -  cost:  0.628068  - MSE:  0.412878298087 - Train Accuracy:  0.509091\n",
      "epoch:  889  -  cost:  0.582508  - MSE:  0.350583801865 - Train Accuracy:  0.509091\n",
      "epoch:  890  -  cost:  0.588523  - MSE:  0.401666573624 - Train Accuracy:  0.509091\n",
      "epoch:  891  -  cost:  0.616605  - MSE:  0.39371465228 - Train Accuracy:  0.509091\n",
      "epoch:  892  -  cost:  0.579767  - MSE:  0.36481022714 - Train Accuracy:  0.509091\n",
      "epoch:  893  -  cost:  0.579346  - MSE:  0.355073793358 - Train Accuracy:  0.509091\n",
      "epoch:  894  -  cost:  0.581036  - MSE:  0.387038806759 - Train Accuracy:  0.509091\n",
      "epoch:  895  -  cost:  0.589951  - MSE:  0.361569476722 - Train Accuracy:  0.509091\n",
      "epoch:  896  -  cost:  0.598454  - MSE:  0.44123251308 - Train Accuracy:  0.509091\n",
      "epoch:  897  -  cost:  0.639599  - MSE:  0.436469034821 - Train Accuracy:  0.509091\n",
      "epoch:  898  -  cost:  0.590928  - MSE:  0.364785283702 - Train Accuracy:  0.509091\n",
      "epoch:  899  -  cost:  0.592339  - MSE:  0.437203490888 - Train Accuracy:  0.509091\n",
      "epoch:  900  -  cost:  0.631371  - MSE:  0.423001026953 - Train Accuracy:  0.509091\n",
      "epoch:  901  -  cost:  0.579773  - MSE:  0.35999339464 - Train Accuracy:  0.509091\n",
      "epoch:  902  -  cost:  0.581347  - MSE:  0.405649734036 - Train Accuracy:  0.509091\n",
      "epoch:  903  -  cost:  0.595987  - MSE:  0.376983951571 - Train Accuracy:  0.509091\n",
      "epoch:  904  -  cost:  0.589063  - MSE:  0.436464471092 - Train Accuracy:  0.509091\n",
      "epoch:  905  -  cost:  0.628047  - MSE:  0.420457657009 - Train Accuracy:  0.509091\n",
      "epoch:  906  -  cost:  0.580333  - MSE:  0.363531285978 - Train Accuracy:  0.509091\n",
      "epoch:  907  -  cost:  0.599344  - MSE:  0.47345296171 - Train Accuracy:  0.509091\n",
      "epoch:  908  -  cost:  0.642453  - MSE:  0.444199834851 - Train Accuracy:  0.509091\n",
      "epoch:  909  -  cost:  0.596213  - MSE:  0.379310034031 - Train Accuracy:  0.509091\n",
      "epoch:  910  -  cost:  0.585071  - MSE:  0.444594881907 - Train Accuracy:  0.509091\n",
      "epoch:  911  -  cost:  0.606472  - MSE:  0.386817972195 - Train Accuracy:  0.509091\n",
      "epoch:  912  -  cost:  0.577851  - MSE:  0.414680539769 - Train Accuracy:  0.509091\n",
      "epoch:  913  -  cost:  0.580632  - MSE:  0.36603473198 - Train Accuracy:  0.509091\n",
      "epoch:  914  -  cost:  0.600376  - MSE:  0.486786613708 - Train Accuracy:  0.509091\n",
      "epoch:  915  -  cost:  0.641723  - MSE:  0.445724686979 - Train Accuracy:  0.509091\n",
      "epoch:  916  -  cost:  0.595664  - MSE:  0.381824176767 - Train Accuracy:  0.509091\n",
      "epoch:  917  -  cost:  0.585942  - MSE:  0.45633809909 - Train Accuracy:  0.509091\n",
      "epoch:  918  -  cost:  0.621921  - MSE:  0.411754065519 - Train Accuracy:  0.509091\n",
      "epoch:  919  -  cost:  0.576199  - MSE:  0.371924126044 - Train Accuracy:  0.509091\n",
      "epoch:  920  -  cost:  0.595295  - MSE:  0.492389036283 - Train Accuracy:  0.509091\n",
      "epoch:  921  -  cost:  0.638779  - MSE:  0.441455939382 - Train Accuracy:  0.509091\n",
      "epoch:  922  -  cost:  0.594425  - MSE:  0.382023513129 - Train Accuracy:  0.509091\n",
      "epoch:  923  -  cost:  0.58347  - MSE:  0.46684405841 - Train Accuracy:  0.509091\n",
      "epoch:  924  -  cost:  0.607668  - MSE:  0.390000295984 - Train Accuracy:  0.509091\n",
      "epoch:  925  -  cost:  0.572221  - MSE:  0.405305907352 - Train Accuracy:  0.509091\n",
      "epoch:  926  -  cost:  0.576394  - MSE:  0.374707537508 - Train Accuracy:  0.509091\n",
      "epoch:  927  -  cost:  0.589943  - MSE:  0.488782308903 - Train Accuracy:  0.509091\n",
      "epoch:  928  -  cost:  0.634403  - MSE:  0.438455048588 - Train Accuracy:  0.509091\n",
      "epoch:  929  -  cost:  0.589833  - MSE:  0.383000711076 - Train Accuracy:  0.509091\n",
      "epoch:  930  -  cost:  0.575695  - MSE:  0.448368012406 - Train Accuracy:  0.509091\n",
      "epoch:  931  -  cost:  0.594283  - MSE:  0.38508557988 - Train Accuracy:  0.509091\n",
      "epoch:  932  -  cost:  0.586721  - MSE:  0.495439308029 - Train Accuracy:  0.509091\n",
      "epoch:  933  -  cost:  0.630168  - MSE:  0.430855563342 - Train Accuracy:  0.509091\n",
      "epoch:  934  -  cost:  0.580183  - MSE:  0.380273007086 - Train Accuracy:  0.509091\n",
      "epoch:  935  -  cost:  0.593363  - MSE:  0.526392669017 - Train Accuracy:  0.509091\n",
      "epoch:  936  -  cost:  0.636336  - MSE:  0.439879675749 - Train Accuracy:  0.509091\n",
      "epoch:  937  -  cost:  0.588878  - MSE:  0.382806818919 - Train Accuracy:  0.509091\n",
      "epoch:  938  -  cost:  0.57912  - MSE:  0.479065378171 - Train Accuracy:  0.509091\n",
      "epoch:  939  -  cost:  0.602622  - MSE:  0.393810993629 - Train Accuracy:  0.509091\n",
      "epoch:  940  -  cost:  0.576252  - MSE:  0.469923840287 - Train Accuracy:  0.509091\n",
      "epoch:  941  -  cost:  0.597996  - MSE:  0.391306930221 - Train Accuracy:  0.509091\n",
      "epoch:  942  -  cost:  0.581107  - MSE:  0.495015601101 - Train Accuracy:  0.509091\n",
      "epoch:  943  -  cost:  0.607055  - MSE:  0.396933537123 - Train Accuracy:  0.509091\n",
      "epoch:  944  -  cost:  0.566777  - MSE:  0.418246350831 - Train Accuracy:  0.509091\n",
      "epoch:  945  -  cost:  0.566564  - MSE:  0.399826703546 - Train Accuracy:  0.509091\n",
      "epoch:  946  -  cost:  0.567627  - MSE:  0.441175124001 - Train Accuracy:  0.509091\n",
      "epoch:  947  -  cost:  0.571983  - MSE:  0.386540098841 - Train Accuracy:  0.509091\n",
      "epoch:  948  -  cost:  0.585835  - MSE:  0.521211658517 - Train Accuracy:  0.509091\n",
      "epoch:  949  -  cost:  0.631833  - MSE:  0.439107489952 - Train Accuracy:  0.509091\n",
      "epoch:  950  -  cost:  0.587165  - MSE:  0.38558986942 - Train Accuracy:  0.509091\n",
      "epoch:  951  -  cost:  0.576722  - MSE:  0.500037545639 - Train Accuracy:  0.509091\n",
      "epoch:  952  -  cost:  0.601873  - MSE:  0.391904068356 - Train Accuracy:  0.509091\n",
      "epoch:  953  -  cost:  0.565199  - MSE:  0.445160719038 - Train Accuracy:  0.509091\n",
      "epoch:  954  -  cost:  0.567222  - MSE:  0.394491007169 - Train Accuracy:  0.509091\n",
      "epoch:  955  -  cost:  0.576474  - MSE:  0.506866233925 - Train Accuracy:  0.509091\n",
      "epoch:  956  -  cost:  0.608269  - MSE:  0.399031688948 - Train Accuracy:  0.509091\n",
      "epoch:  957  -  cost:  0.563057  - MSE:  0.426581674531 - Train Accuracy:  0.509091\n",
      "epoch:  958  -  cost:  0.562531  - MSE:  0.421684773977 - Train Accuracy:  0.509091\n",
      "epoch:  959  -  cost:  0.562109  - MSE:  0.416535866715 - Train Accuracy:  0.509091\n",
      "epoch:  960  -  cost:  0.561661  - MSE:  0.422847844927 - Train Accuracy:  0.509091\n",
      "epoch:  961  -  cost:  0.561293  - MSE:  0.41697340103 - Train Accuracy:  0.509091\n",
      "epoch:  962  -  cost:  0.56079  - MSE:  0.42450756178 - Train Accuracy:  0.509091\n",
      "epoch:  963  -  cost:  0.560298  - MSE:  0.427454486856 - Train Accuracy:  0.509091\n",
      "epoch:  964  -  cost:  0.559698  - MSE:  0.435446975474 - Train Accuracy:  0.509091\n",
      "epoch:  965  -  cost:  0.559102  - MSE:  0.435927090662 - Train Accuracy:  0.509091\n",
      "epoch:  966  -  cost:  0.558718  - MSE:  0.423317168151 - Train Accuracy:  0.509091\n",
      "epoch:  967  -  cost:  0.559233  - MSE:  0.449353135884 - Train Accuracy:  0.509091\n",
      "epoch:  968  -  cost:  0.569276  - MSE:  0.388972081085 - Train Accuracy:  0.509091\n",
      "epoch:  969  -  cost:  0.596162  - MSE:  0.592249895765 - Train Accuracy:  0.509091\n",
      "epoch:  970  -  cost:  0.651252  - MSE:  0.457165708043 - Train Accuracy:  0.509091\n",
      "epoch:  971  -  cost:  0.615073  - MSE:  0.40637704438 - Train Accuracy:  0.509091\n",
      "epoch:  972  -  cost:  0.559422  - MSE:  0.410287660852 - Train Accuracy:  0.509091\n",
      "epoch:  973  -  cost:  0.567232  - MSE:  0.50511472748 - Train Accuracy:  0.509091\n",
      "epoch:  974  -  cost:  0.602643  - MSE:  0.389955910297 - Train Accuracy:  0.509091\n",
      "epoch:  975  -  cost:  0.557198  - MSE:  0.453508283786 - Train Accuracy:  0.509091\n",
      "epoch:  976  -  cost:  0.559288  - MSE:  0.410397372576 - Train Accuracy:  0.509091\n",
      "epoch:  977  -  cost:  0.580785  - MSE:  0.564496832348 - Train Accuracy:  0.509091\n",
      "epoch:  978  -  cost:  0.631601  - MSE:  0.437939125797 - Train Accuracy:  0.509091\n",
      "epoch:  979  -  cost:  0.577408  - MSE:  0.384420648829 - Train Accuracy:  0.509091\n",
      "epoch:  980  -  cost:  0.57708  - MSE:  0.56195727989 - Train Accuracy:  0.509091\n",
      "epoch:  981  -  cost:  0.62635  - MSE:  0.434474423563 - Train Accuracy:  0.509091\n",
      "epoch:  982  -  cost:  0.581501  - MSE:  0.392648154126 - Train Accuracy:  0.509091\n",
      "epoch:  983  -  cost:  0.587225  - MSE:  0.609074905089 - Train Accuracy:  0.509091\n",
      "epoch:  984  -  cost:  0.640602  - MSE:  0.449810183691 - Train Accuracy:  0.509091\n",
      "epoch:  985  -  cost:  0.592369  - MSE:  0.395258789127 - Train Accuracy:  0.509091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  986  -  cost:  0.565617  - MSE:  0.537465833773 - Train Accuracy:  0.509091\n",
      "epoch:  987  -  cost:  0.599354  - MSE:  0.396979064554 - Train Accuracy:  0.509091\n",
      "epoch:  988  -  cost:  0.556892  - MSE:  0.49614479041 - Train Accuracy:  0.509091\n",
      "epoch:  989  -  cost:  0.570228  - MSE:  0.397518507435 - Train Accuracy:  0.509091\n",
      "epoch:  990  -  cost:  0.580109  - MSE:  0.608247234792 - Train Accuracy:  0.509091\n",
      "epoch:  991  -  cost:  0.63298  - MSE:  0.443713743306 - Train Accuracy:  0.509091\n",
      "epoch:  992  -  cost:  0.578404  - MSE:  0.394700990526 - Train Accuracy:  0.509091\n",
      "epoch:  993  -  cost:  0.579094  - MSE:  0.615998539033 - Train Accuracy:  0.509091\n",
      "epoch:  994  -  cost:  0.630178  - MSE:  0.44080745576 - Train Accuracy:  0.509091\n",
      "epoch:  995  -  cost:  0.578374  - MSE:  0.396155303835 - Train Accuracy:  0.509091\n",
      "epoch:  996  -  cost:  0.583703  - MSE:  0.6312565966 - Train Accuracy:  0.509091\n",
      "epoch:  997  -  cost:  0.63847  - MSE:  0.454765001614 - Train Accuracy:  0.509091\n",
      "epoch:  998  -  cost:  0.583102  - MSE:  0.402391085913 - Train Accuracy:  0.509091\n",
      "epoch:  999  -  cost:  0.581721  - MSE:  0.630061354127 - Train Accuracy:  0.509091\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x:X_train, y_:Y_train})\n",
    "    cost = sess.run(cost_function,feed_dict={x:X_train, y_:Y_train})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x:test_x, y_:test_y})))\n",
    "    pred_y = sess.run(y,feed_dict={x:X_test} )\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - Y_test))\n",
    "    mse_ = sess.run(mse)\n",
    "    accuracy = (sess.run(accuracy,feed_dict={x:X_train, y_:Y_train}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    print('epoch: ', epoch,' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %s /home/baka/Project/eternal-Learning/Tensorflowmodel.ckpt\n"
     ]
    }
   ],
   "source": [
    "save_path = saver.save(sess,model_save_path+\"model.ckpt\")\n",
    "print(\"Model saved in file: %s\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f361a217c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  [[ 1.00598848 -0.27480122]\n",
      " [ 0.37220466 -0.10167342]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.89151478 -0.51669633]\n",
      " [ 0.          0.        ]\n",
      " [ 0.40165958 -0.10971949]\n",
      " [ 2.52431583 -0.6895557 ]\n",
      " [ 1.68786907 -0.46106738]\n",
      " [ 2.1839695  -0.5965848 ]\n",
      " [ 1.24141967 -0.33911285]\n",
      " [ 0.          0.        ]\n",
      " [ 2.06629348 -0.56443983]\n",
      " [ 2.0714829  -0.62282556]\n",
      " [ 1.77212667 -0.48408362]\n",
      " [ 1.91593039 -0.52336586]\n",
      " [ 0.          0.        ]\n",
      " [ 1.87823737 -0.51306939]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.70424008 -0.46553937]\n",
      " [ 1.96880281 -0.53780872]\n",
      " [ 0.27101102 -0.07403082]\n",
      " [ 0.          0.        ]\n",
      " [ 0.11970146 -0.03269829]\n",
      " [ 0.17768888 -0.04853845]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.92844081 -0.79994857]\n",
      " [ 3.26225114 -0.89113402]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.32717466 -0.36253816]\n",
      " [ 2.41388154 -0.65938884]\n",
      " [ 0.63260734 -0.17280643]\n",
      " [ 0.99908721 -0.27291602]\n",
      " [ 0.46053526 -0.12580228]\n",
      " [ 0.64672345 -0.17666245]\n",
      " [ 1.4086988  -0.38480771]\n",
      " [ 0.          0.        ]\n",
      " [ 0.80578804 -0.22011338]]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.square(pred_y - Y_test))\n",
    "print(\"Test Accuracy: \", (sess.run(y, feed_dict={x:X_test, y_:Y_test} )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6301\n"
     ]
    }
   ],
   "source": [
    "pred_y = sess.run(y, feed_dict={x:X_test})\n",
    "mse = tf.reduce_mean(tf.square(pred_y- Y_test))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
